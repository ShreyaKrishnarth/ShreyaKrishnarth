# -*- coding: utf-8 -*-
"""Final music classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S9d_NQB1WJbQH8OoQtK4w8wsEm-9jUdK

# Installation of Packages
"""

pip install  umap-learn UMAP plotly

"""# Mounting G-drive"""

from google.colab import drive
drive.mount('/content/drive')

"""# Importing Libraries

"""

# Commented out IPython magic to ensure Python compatibility.
 #Import the core libraries required for data handling, machine learning algorithms, and audio processing tasks.

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import  SpectralClustering, KMeans
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, VotingClassifier
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import librosa
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objs as go
import plotly.express as px
from mpl_toolkits.mplot3d import Axes3D
import umap
from sklearn.impute import KNNImputer
from scipy.stats import shapiro
from statsmodels.graphics.gofplots import qqplot
# %matplotlib inline
from scipy.stats import zscore
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.preprocessing import normalize
from sklearn.metrics.pairwise import rbf_kernel
from scipy.sparse import csgraph
from sklearn.manifold import TSNE
from sklearn.neighbors import NearestNeighbors
from sklearn.manifold import SpectralEmbedding
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import rbf_kernel, polynomial_kernel, sigmoid_kernel
from scipy.sparse import csgraph
from sklearn.impute import SimpleImputer
from scipy.linalg import eigh
from sklearn.model_selection import KFold, cross_val_score
import librosa.display
import time
from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score
from sklearn.feature_selection import SelectKBest, chi2
import math
from sklearn.utils.extmath import randomized_svd
from sklearn.neural_network import MLPRegressor
import warnings
warnings.filterwarnings("ignore")

"""# Loading Dataset"""

# Load the dataset from Google Drive and apply preprocessing to extract relevant audio features.

data = pd.read_csv('/content/drive/MyDrive/old Spotify data.csv')

"""# Data Pre-processing"""

# Inspect the dataset
print("Dataset Information:")
print(data.info())
print("\nSummary Statistics:")
print(data.describe())

 # Verify the dataset for any missing values.


missing_values = data.isnull().sum()
print("\nMissing Values:")
print(missing_values)
# Handle missing values
# If missing values exist, decide how to handle them (drop or impute)
if missing_values.any():
    data.dropna(inplace=True)  # Example: Dropping rows with missing values# List of columns to be removed

# Use KNN Imputation to address and fill in missing values in the dataset.
imputer = KNNImputer(n_neighbors=5)
data_imputed = pd.DataFrame(imputer.fit_transform(data.select_dtypes(include=['float64', 'int64'])), columns=data.select_dtypes(include=['float64', 'int64']).columns)


# Confirm that all missing values have been successfully handled.
missing_values_after_imputation = data.isnull().sum()
print("\nMissing Values after KNN imputation:")
print(missing_values_after_imputation)


# Remove the unnecessary specified columns from the dataset
columns_to_drop = [
      'Unnamed:0','track_id', 'duration_ms', 'explicit',
    'key', 'mode', 'speechiness', 'time_signature','instrumentalness','popularity'
]

# Dropping the specified columns from the dataset
data = data.drop(columns=columns_to_drop, errors='ignore')

# After dropping, verify the dataset to confirm the specified columns have been successfully removed.
print("Columns after dropping the specified columns:")
print(data.columns)

# Verify that 'Unnamed: 0' is not in the remaining columns
if 'Unnamed: 0' not in data.columns:
    print("'Unnamed: 0' column has been successfully removed.")
else:
    print("Warning: 'Unnamed: 0' column is still present in the dataset.")

# Remove any column that starts with 'Unnamed:'
data = data.loc[:, ~data.columns.str.startswith('Unnamed:')]

# Ensure 'Unnamed: 0' is no longer present in the columns
if 'Unnamed: 0' not in data.columns:
    print("'Unnamed: 0' column has been successfully removed.")
else:
    print("Warning: 'Unnamed: 0' column is still present in the dataset.")

print(data.columns)

# drop the specified genres
#keep_genres=['classical','dance','drum-and-bass','electronic',
             #'hip-hop','house','metal','party','pop','r-n-b']
drop_genres = [
    'acoustic', 'alternative', 'afrobeat', 'alt-rock', 'ambient', 'anime', 'black-metal',
    'bluegrass', 'blues', 'brazil', 'breakbeat', 'british', 'cantopop', 'chicago-house',
    'children', 'chill', 'club', 'comedy', 'dancehall', 'death-metal', 'deep-house',
    'detroit-techno', 'disney', 'dub', 'edm', 'electro', 'emo', 'folk', 'forro', 'french',
    'funk', 'garage', 'german', 'gospel', 'goth', 'grindcore', 'groove', 'grunge', 'guitar',
    'happy', 'hard-rock', 'hardcore', 'hardstyle', 'heavy-metal', 'honky-tonk', 'idm',
    'indian', 'indie-pop', 'indie', 'industrial', 'iranian', 'j-dance', 'j-idol', 'j-pop',
    'j-rock', 'k-pop', 'kids', 'latin', 'latino', 'malay', 'mandopop', 'metalcore',
    'minimal-techno', 'mpb', 'new-age', 'opera', 'pagode', 'piano', 'pop-film',
    'power-pop', 'progressive-house', 'psych-rock', 'punk-rock', 'punk', 'reggae',
    'reggaeton', 'rock-n-roll', 'rockabilly', 'romance', 'sad', 'salsa', 'samba',
    'sertanejo', 'show-tunes', 'singer-songwriter', 'ska', 'sleep', 'songwriter',
    'soul', 'spanish', 'study', 'swedish', 'synth-pop', 'tango', 'trip-hop', 'turkish',
    'world-music'
        'world-music', 'jazz', 'rock', 'disco',  # Previously added genres
    'country', 'dubstep', 'techno', 'trance'  # Newly added genres
]

# Filter out rows that contain the genres marked for removal
filtered_data = data[~data['track_genre'].isin(drop_genres)]

# Print the remaining number of rows after dropping the specified genres
print(f"Total number of rows left after dropping specified genres: {filtered_data.shape[0]}")

# Use value_counts directly on the 'track_genre' column and then print
print(filtered_data['track_genre'].value_counts())

"""# Outlier Detection and Removal"""

# Function to detect outliers using the IQR method
def detect_outliers_iqr(filtered_data):
    outliers_dict = {}
    for column in filtered_data.select_dtypes(include=['float64', 'int64']).columns:
        Q1 = filtered_data[column].quantile(0.25)
        Q3 = filtered_data[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = filtered_data[(data[column] < lower_bound) | (filtered_data[column] > upper_bound)]
        outliers_count = outliers.shape[0]
        outliers_dict[column] = outliers_count
    return outliers_dict

# Detecting outliers in the dataset
outliers = detect_outliers_iqr(filtered_data)

# Displaying the number of outliers for each numerical column
print("Number of outliers in each numerical column:")
for column, count in outliers.items():
    print(f"{column}: {count} outliers")

# Function to identify  outliers in a specific column using the IQR method
def extract_outliers(filtered_data, column):
    Q1 = filtered_data[column].quantile(0.25)
    Q3 = filtered_data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = filtered_data[(filtered_data[column] < lower_bound) | (filtered_data[column] > upper_bound)]
    return outliers[column]

# Extracting outliers for each relevant column
danceability_outliers = extract_outliers(filtered_data, 'danceability')
loudness_outliers = extract_outliers(filtered_data, 'loudness')
#instrumentalness_outliers = extract_outliers(data, 'instrumentalness')
liveness_outliers = extract_outliers(filtered_data, 'liveness')
tempo_outliers = extract_outliers(filtered_data, 'tempo')

# Displaying the identified outlier values
print("Outlier values in 'danceability':")
print(danceability_outliers)

print("\nOutlier values in 'loudness':")
print(loudness_outliers)

print("\nOutlier values in 'instrumentalness':")
#print(instrumentalness_outliers)

print("\nOutlier values in 'liveness':")
print(liveness_outliers)

print("\nOutlier values in 'tempo':")
print(tempo_outliers)

categorical_cols_to_plot = filtered_data.select_dtypes(include=['object','category']).columns.to_list()

# select the numerical variables
numerical_cols_to_plot = filtered_data.select_dtypes(include=['int','float']).columns.to_list()

def shapiro_test(data:pd.DataFrame, col:str):
    stat, p_value = shapiro(filtered_data[col])
    if p_value < 0.05:
        return p_value, 'No Normal Ditribution'
    else:
        return p_value, 'Normal Distribution'

def univariate_numerical_plot(data:pd.DataFrame, var:str):
  """
  Args:
    - data(pd.DataFrame): data.
    - var(str):variable a trazar.
  """
  ax = plt.figure(constrained_layout = False, figsize = (12,5.8)).subplot_mosaic("""AD
                                                                                 BD""")
  sns.boxenplot(filtered_data, x= var, ax = ax['A'], color = 'lime')
  sns.stripplot(filtered_data, x = var, alpha = 0.5, color = 'darkblue', ax = ax['A'])
  sns.histplot(filtered_data, x = var, kde = True,line_kws = {'linewidth':1.8}, color = '#FF5733', ax = ax['B'])
  qqplot(filtered_data[var], line = 's', ax = ax['D'])
  df_info = filtered_data[var].describe()
  ax['A'].set_xlabel('')
  ax['A'].set_title(f'Mean={round(df_info[1],2)} | Std={round(df_info[2],2)} | Median={round(df_info[5],2)}', fontsize = 9, fontweight='bold')
  ax['B'].set_xlabel('')
  ax['D'].set_title(f'QQ-Plot | Shapiro test: p-value={round(shapiro_test(filtered_data,var)[0],3)} | {shapiro_test(filtered_data,var)[1]}',fontsize=9, fontweight='bold')
  plt.suptitle(f'Distribution of variable {var}',fontsize = 14, fontweight = 'bold', color = 'darkred')
  plt.tight_layout()
  plt.subplots_adjust(top=0.9)
  plt.show()

for var in numerical_cols_to_plot:
    univariate_numerical_plot(filtered_data, var)

print(filtered_data.shape)

# Function to remove outliers using the Z-score method with a fixed threshold
def remove_outliers_zscore(filtered_data, threshold=2.5):
    z_scores = np.abs(zscore(filtered_data.select_dtypes(include=[np.number])))
    return filtered_data[(z_scores < threshold).all(axis=1)]

# Iteratively remove outliers from each column until none remain
def iterative_cleaning(filtered_data, threshold=2.5, max_iterations=100):
    for _ in range(max_iterations):
        data_cleaned = remove_outliers_zscore(filtered_data, threshold)
        remaining_outliers = (np.abs(zscore(data_cleaned.select_dtypes(include=[np.number]))) > threshold).sum().sum()
        if remaining_outliers == 0:
            break
        filtered_data = data_cleaned
    return data_cleaned

# Apply the iterative outlier removal process to the dataset
data_cleaned_zscore = iterative_cleaning(filtered_data, threshold=2.5, max_iterations=100)

# Final check
print("Number of remaining outliers after final cleaning:")
z_scores_after_final = np.abs(zscore(data_cleaned_zscore.select_dtypes(include=[np.number])))
remaining_outliers_final = (z_scores_after_final > 2.5).sum(axis=0)
for column, count in zip(data_cleaned_zscore.select_dtypes(include=[np.number]).columns, remaining_outliers_final):
    print(f"{column}: {count} outliers")

# Standardize the audio features to have zero mean and unit variance
#Define the relevant audio features for analysis
audio_features = ['danceability', 'energy', 'loudness', 'valence', 'tempo']
scaler = StandardScaler()
data_cleaned_zscore [audio_features] = scaler.fit_transform(data_cleaned_zscore [audio_features])

# To Display the first few rows of the sampled and standardized data
data_cleaned_zscore.head()

"""# Data Visualisation"""

# Function to visualize the data
def visualize_cleaned_data(data, columns):
    for column in columns:
        plt.figure(figsize=(12, 5))

        # Box Plot
        plt.subplot(1, 2, 1)
        sns.boxplot(data[column])
        plt.title(f'Box Plot of {column}')

        # Distribution Plot
        plt.subplot(1, 2, 2)
        sns.histplot(data[column], kde=True)
        plt.title(f'Distribution of {column}')

        plt.show()

# Function to generate a  correlation heatmap and 3D scatter plot
def correlation_heatmap_3d_scatter(data):
    # Assuming 'audio_features' is defined and contains the relevant audio columns
    audio_features = ['danceability', 'energy', 'loudness', 'valence', 'tempo']

    # Computing the correlation matrix for selected audio features
    correlation = data_cleaned_zscore[audio_features].corr()

    # Plotting the Correlation Heatmap
    plt.figure(figsize=(12, 8))
    sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f')
    plt.title("Correlation Heatmap of Audio Features")
    plt.show()

    # Plotting the 3D Scatter Plot using Plotly
    fig = px.scatter_3d(data_cleaned_zscore,
                        x='danceability',
                        y='energy',
                        z='valence',
                        color='track_genre',
                        title='3D Scatter Plot of Audio Features by Genre')
    fig.show()

# First, clean the data using the provided function
data_cleaned = iterative_cleaning(data_cleaned_zscore, threshold=2.5)

# Select numerical columns to visualize
numerical_columns = data_cleaned.select_dtypes(include=[np.number]).columns

# Visualize the cleaned data
visualize_cleaned_data(data_cleaned, numerical_columns)

# Then, create the correlation heatmap and 3D scatter plot
correlation_heatmap_3d_scatter(data_cleaned)

# Filter for top 10 or 20 genres based on count or relevance
top_genres = data_cleaned['track_genre'].value_counts().nlargest(10).index
filtered_data = data_cleaned[data_cleaned['track_genre'].isin(top_genres)]

# Function to remove outliers using the IQR method
def remove_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]

# Apply outlier removal to the filtered data
filtered_data = pd.concat(
    [remove_outliers_iqr(filtered_data[filtered_data['track_genre'] == genre], 'danceability')
     for genre in top_genres]
)

# To generate a boxplot for the filtered data without outliers
plt.figure(figsize=(10, 6))
sns.boxplot(x='danceability', y='track_genre', data=filtered_data)
plt.xticks(rotation=90)
plt.title("Box Plot of Danceability by Top Track Genres (Outliers Removed)")
plt.show()

# Function to remove outliers using IQR (already defined)
def remove_outliers_iqr(data):
    numeric_data = data.select_dtypes(include=[np.number])  # Select only numeric columns
    Q1 = numeric_data.quantile(0.25)
    Q3 = numeric_data.quantile(0.75)
    IQR = Q3 - Q1
    is_not_outlier = ~((numeric_data < (Q1 - 1.5 * IQR)) | (numeric_data > (Q3 + 1.5 * IQR))).any(axis=1)
    return data[is_not_outlier]

# Remove outliers for 'energy'
filtered_data_no_outliers_energy = remove_outliers_iqr(filtered_data[['energy']])
filtered_data_no_outliers_energy['track_genre'] = filtered_data.loc[filtered_data_no_outliers_energy.index, 'track_genre']

# Plot for Energy without outliers
plt.figure(figsize=(10, 6))
sns.boxplot(x='energy', y='track_genre', data=filtered_data_no_outliers_energy)
plt.xticks(rotation=90)
plt.title("Box Plot of Energy by Top Track Genres (Outliers Removed)")
plt.show()

# Apply Z-score to remove outliers more strictly
z_scores = zscore(filtered_data['liveness'])
abs_z_scores = np.abs(z_scores)

# Consider any data point with a Z-score greater than 2.5 as an outlier
filtered_data_no_outliers_liveness = filtered_data[abs_z_scores < 2.5]

# Plot the boxplot for 'liveness' after removing outliers using Z-score method
plt.figure(figsize=(10, 6))
sns.boxplot(x='liveness', y='track_genre', data=filtered_data_no_outliers_liveness)
plt.xticks(rotation=90)
plt.title("Box Plot of Liveness by Top Track Genres (Stricter Outliers Removed)")
plt.show()

# Final Check after Feature Engineering
print("\nFinal Dataset after Feature Engineering:")
print(data_cleaned_zscore.head())

# Select a random sample of 2000 rows from the dataset
sampled_data = data_cleaned_zscore#.sample(n=2000, random_state=42)
print(sampled_data['track_genre'])

# Correlation Heatmap:
# Purpose: Visualize the relationships between audio features and their correlation with song popularity.
# Usefulness: Helps identify which features are strongly associated with popularity, aiding in feature selection for modeling.
# Filter numerical columns to compute the correlation matrix.
numerical_columns = sampled_data.select_dtypes(include=['float64', 'int64']).columns
correlation = sampled_data[numerical_columns].corr()

# Plot the correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Correlation Heatmap of Audio Features")
plt.show()

# Distribution Plots:
# Purpose: Visualize the distribution of audio features such as danceability, energy, etc.
# Usefulness: These plots help understand feature distributions across the dataset, aiding in decisions for normalization or transformation if necessary.
sns.histplot(sampled_data['danceability'], kde=True)
plt.title("Distribution of Danceability")
plt.show()

# Bar Plots:
# Purpose: Visualize categorical data to highlight differences between groups.
# Usefulness: Bar plots showing genre or mood popularity can effectively summarize your model's output and insights
famous = sampled_data.sort_values("track_genre", ascending=False).head(10)
sns.barplot(y='track_genre', x='danceability', data=famous).set(title="Top 10 Genres by Popularity")
plt.show()

X = sampled_data[audio_features]

# Step 4: Apply K-Means clustering to the audio features and map clusters to moods
kmeans = KMeans(n_clusters=10, random_state=42)  # 10 clusters for different moods
sampled_data['cluster'] = kmeans.fit_predict(sampled_data[audio_features])

# Map each cluster to a corresponding mood label
mood_map = {0: 'Happy', 1: 'Sad', 2: 'Energetic', 3: 'Calm', 4: 'Romantic',
            5: 'Aggressive', 6: 'Melancholic', 7: 'Uplifting', 8: 'Chill', 9: 'Party'}
sampled_data['mood'] = sampled_data['cluster'].map(mood_map)

print(sampled_data['mood'])



"""# Spectral Clustering Analysis to classify the data"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.manifold import TSNE
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import rbf_kernel
from scipy.sparse import csgraph
from sklearn.decomposition import PCA
import pandas as pd

# Assuming X and sampled_data are already loaded

def normalized_spectral_clustering(X, n_clusters=10, affinity='rbf', gamma=1.0, n_neighbors=15):
    if affinity == 'rbf':
        affinity_matrix = rbf_kernel(X, gamma=gamma)
    elif affinity == 'nearest_neighbors':
        neighbors = NearestNeighbors(n_neighbors=n_neighbors).fit(X)
        affinity_matrix = neighbors.kneighbors_graph(X).toarray()

    laplacian = csgraph.laplacian(affinity_matrix, normed=True)
    eigenvalues, eigenvectors = np.linalg.eigh(laplacian)
    X_spec = eigenvectors[:, :n_clusters]
    X_spec = normalize(X_spec)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(X_spec)

    return labels

# Apply normalized spectral clustering with RBF affinity
labels_rbf = normalized_spectral_clustering(X, n_clusters=10, affinity='rbf', gamma=1.0)
sampled_data['Normalized Spectral Clustering (RBF)'] = labels_rbf

# Apply normalized spectral clustering with nearest neighbors affinity
labels_nn = normalized_spectral_clustering(X, n_clusters=10, affinity='nearest_neighbors', n_neighbors=15)
sampled_data['Normalized Spectral Clustering (Nearest Neighbors)'] = labels_nn

# Function to evaluate the clustering results
def evaluate_clustering(X, labels, title):
    silhouette_avg = silhouette_score(X, labels)
    calinski_harabasz = calinski_harabasz_score(X, labels)
    davies_bouldin = davies_bouldin_score(X, labels)

    print(f"\n{title} Evaluation:")
    print(f"Silhouette Score: {silhouette_avg:.3f}")
    print(f"Calinski-Harabasz Score: {calinski_harabasz:.3f}")
    print(f"Davies-Bouldin Score: {davies_bouldin:.3f}")

# Function to map clusters to the most frequent genre/mood
def get_cluster_labels(labels, genre_labels, mood_labels, n_clusters=10):
    cluster_genre = []
    cluster_mood = []
    for cluster in range(n_clusters):
        mask = labels == cluster
        most_frequent_genre = genre_labels[mask].mode()[0]
        most_frequent_mood = mood_labels[mask].mode()[0]
        cluster_genre.append(most_frequent_genre)
        cluster_mood.append(most_frequent_mood)
    return cluster_genre, cluster_mood

# Plot function with aggregated cluster labels for genre and mood
def plot_tsne_with_color_labels(X_tsne_2d, labels, genre_labels, mood_labels, title):
    # Get the representative genre and mood labels for each cluster
    cluster_genre, cluster_mood = get_cluster_labels(labels, genre_labels, mood_labels)

    plt.figure(figsize=(12, 8))
    scatter = plt.scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], c=labels, cmap='Spectral', s=5)

    # Create a colorbar with the representative genre and mood for each cluster
    cbar = plt.colorbar(scatter, boundaries=np.arange(11)-0.5)
    cbar.set_ticks(np.arange(10))
    cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

    plt.title(f't-SNE 2D Visualization of {title}', fontsize=15)
    plt.xlabel("t-SNE Component 1")
    plt.ylabel("t-SNE Component 2")
    plt.show()

# Apply t-SNE for 2D visualization
tsne_2d = TSNE(n_components=2, perplexity=30, n_iter=300)
X_tsne_2d_rbf = tsne_2d.fit_transform(X)
X_tsne_2d_nn = tsne_2d.fit_transform(X)

# Use genre and mood labels from your dataset
genre_labels = sampled_data['track_genre']
mood_labels = sampled_data['mood']

# Evaluate Normalized Spectral Clustering (RBF)
evaluate_clustering(X, labels_rbf, "Normalized Spectral Clustering (RBF)")
# Plot t-SNE with aggregated genre and mood names for Normalized Spectral Clustering (RBF)
plot_tsne_with_color_labels(X_tsne_2d_rbf, labels_rbf, genre_labels, mood_labels, "Normalized Spectral Clustering (RBF)")

# Evaluate Normalized Spectral Clustering (Nearest Neighbors)
evaluate_clustering(X, labels_nn, "Normalized Spectral Clustering (Nearest Neighbors)")
# Plot t-SNE with aggregated genre and mood names for Normalized Spectral Clustering (Nearest Neighbors)
plot_tsne_with_color_labels(X_tsne_2d_nn, labels_nn, genre_labels, mood_labels, "Normalized Spectral Clustering (Nearest Neighbors)")

# Apply PCA after Normalized Spectral Clustering
pca_2d = PCA(n_components=2)
X_pca_2d = pca_2d.fit_transform(X)

# Get the cluster labels (most frequent genre and mood per cluster)
cluster_genre, cluster_mood = get_cluster_labels(labels_rbf, genre_labels, mood_labels)

# 2D PCA Visualization for Normalized Spectral Clustering
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1],
                      c=sampled_data['Normalized Spectral Clustering (RBF)'], cmap='Spectral', s=50)
plt.title('PCA 2D Visualization - Normalized Spectral Clustering (RBF)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')

# Create a colorbar with cluster genre and mood labels
cbar = plt.colorbar(scatter, ticks=np.arange(10))
cbar.set_label('Cluster Labels (Genre / Mood)')
cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

plt.show()

# Calculate WCSS for Kernel Spectral Clustering (Polynomial)
def calculate_wcss(X, labels):
    # Get unique cluster labels
    unique_labels = np.unique(labels)

    # Initialize WCSS
    wcss = 0

    # Calculate the centroid for each cluster and sum the WCSS
    for label in unique_labels:
        # Get points in the current cluster
        cluster_points = X[labels == label]

        # Calculate the centroid of the current cluster
        centroid = np.mean(cluster_points, axis=0)

        # Calculate the sum of squared distances from points to the centroid
        squared_distances = np.sum((cluster_points - centroid) ** 2)

        # Add to the total WCSS
        wcss += squared_distances

    return wcss

# Calculate WCSS for these clusters
wcss_rbf = calculate_wcss(X, labels_rbf)
print(f"WCSS for the Normalized Spectral Clustering (RBF): {wcss_rbf}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.manifold import TSNE
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import rbf_kernel
from scipy.sparse import csgraph
from sklearn.decomposition import PCA
import pandas as pd
import plotly.express as px

# Assuming X and sampled_data are already loaded

def unnormalized_spectral_clustering(X, n_clusters=10, affinity='rbf'):
    if affinity == 'rbf':
        affinity_matrix = rbf_kernel(X, gamma=1.0)
    elif affinity == 'nearest_neighbors':
        neighbors = NearestNeighbors(n_neighbors=15).fit(X)
        affinity_matrix = neighbors.kneighbors_graph(X).toarray()

    laplacian = csgraph.laplacian(affinity_matrix, normed=False)
    eigenvalues, eigenvectors = np.linalg.eigh(laplacian)
    X_spec = eigenvectors[:, :n_clusters]

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(X_spec)

    return labels

# Apply unnormalized spectral clustering with RBF affinity
labels_rbf = unnormalized_spectral_clustering(X, n_clusters=10, affinity='rbf')
sampled_data['Unnormalized Spectral Clustering (RBF)'] = labels_rbf

# Apply unnormalized spectral clustering with nearest neighbors affinity
labels_nn = unnormalized_spectral_clustering(X, n_clusters=10, affinity='nearest_neighbors')
sampled_data['Unnormalized Spectral Clustering (Nearest Neighbors)'] = labels_nn

# Function to evaluate the clustering results
def evaluate_clustering(X, labels, title):
    silhouette_avg = silhouette_score(X, labels)
    calinski_harabasz = calinski_harabasz_score(X, labels)
    davies_bouldin = davies_bouldin_score(X, labels)

    print(f"\n{title} Evaluation:")
    print(f"Silhouette Score: {silhouette_avg:.3f}")
    print(f"Calinski-Harabasz Score: {calinski_harabasz:.3f}")
    print(f"Davies-Bouldin Score: {davies_bouldin:.3f}")

# Function to map clusters to the most frequent genre/mood
def get_cluster_labels(labels, genre_labels, mood_labels, n_clusters=10):
    cluster_genre = []
    cluster_mood = []
    for cluster in range(n_clusters):
        mask = labels == cluster
        most_frequent_genre = genre_labels[mask].mode()[0]
        most_frequent_mood = mood_labels[mask].mode()[0]
        cluster_genre.append(most_frequent_genre)
        cluster_mood.append(most_frequent_mood)
    return cluster_genre, cluster_mood

# Plot function with aggregated cluster labels for genre and mood
def plot_tsne_with_color_labels(X_tsne_2d, labels, genre_labels, mood_labels, title):
    # Get the representative genre and mood labels for each cluster
    cluster_genre, cluster_mood = get_cluster_labels(labels, genre_labels, mood_labels)

    plt.figure(figsize=(12, 8))
    scatter = plt.scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], c=labels, cmap='Spectral', s=5)

    # Create a colorbar with the representative genre and mood for each cluster
    cbar = plt.colorbar(scatter, boundaries=np.arange(11)-0.5)
    cbar.set_ticks(np.arange(10))
    cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

    plt.title(f't-SNE 2D Visualization of {title}', fontsize=15)
    plt.xlabel("t-SNE Component 1")
    plt.ylabel("t-SNE Component 2")
    plt.show()

# Apply t-SNE for 2D visualization
tsne_2d = TSNE(n_components=2, perplexity=30, n_iter=300)
X_tsne_2d_rbf = tsne_2d.fit_transform(X)
X_tsne_2d_nn = tsne_2d.fit_transform(X)

# Use genre and mood labels from your dataset
genre_labels = sampled_data['track_genre']
mood_labels = sampled_data['mood']

# Evaluate Unnormalized Spectral Clustering (RBF)
evaluate_clustering(X, labels_rbf, "Unnormalized Spectral Clustering (RBF)")
# Plot t-SNE with aggregated genre and mood names for Unnormalized Spectral Clustering (RBF)
plot_tsne_with_color_labels(X_tsne_2d_rbf, labels_rbf, genre_labels, mood_labels, "Unnormalized Spectral Clustering (RBF)")

# Evaluate Unnormalized Spectral Clustering (Nearest Neighbors)
evaluate_clustering(X, labels_nn, "Unnormalized Spectral Clustering (Nearest Neighbors)")
# Plot t-SNE with aggregated genre and mood names for Unnormalized Spectral Clustering (Nearest Neighbors)
plot_tsne_with_color_labels(X_tsne_2d_nn, labels_nn, genre_labels, mood_labels, "Unnormalized Spectral Clustering (Nearest Neighbors)")

# Apply PCA after Unnormalized Spectral Clustering
pca_2d = PCA(n_components=2)
X_pca_2d = pca_2d.fit_transform(X)

# Get the cluster labels (most frequent genre and mood per cluster)
cluster_genre, cluster_mood = get_cluster_labels(labels_rbf, genre_labels, mood_labels)

# 2D PCA Visualization for Unnormalized Spectral Clustering
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1],
                      c=sampled_data['Unnormalized Spectral Clustering (RBF)'], cmap='Spectral', s=50)
plt.title('PCA 2D Visualization - Unnormalized Spectral Clustering (RBF)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')

# Create a colorbar with cluster genre and mood labels
cbar = plt.colorbar(scatter, ticks=np.arange(10))
cbar.set_label('Cluster Labels (Genre / Mood)')
cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

plt.show()

# For Unnormalized Spectral Clustering
labels_unnorm = unnormalized_spectral_clustering(X, n_clusters=10, affinity='rbf')
wcss_unnorm = calculate_wcss(X, labels_unnorm)
print(f"WCSS for the Unnormalized Spectral Clustering (RBF): {wcss_unnorm}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.manifold import TSNE
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import rbf_kernel
from sklearn.decomposition import PCA
from sklearn.manifold import SpectralEmbedding
import pandas as pd
import plotly.express as px

# Assuming X and sampled_data are already loaded

def diffusion_map_spectral_clustering(X, n_clusters=10, affinity='rbf'):
    if affinity == 'rbf':
        affinity_matrix = rbf_kernel(X, gamma=1.0)
    elif affinity == 'nearest_neighbors':
        neighbors = NearestNeighbors(n_neighbors=15).fit(X)
        affinity_matrix = neighbors.kneighbors_graph(X).toarray()

    embedding = SpectralEmbedding(n_components=n_clusters, affinity='precomputed')
    X_diff_map = embedding.fit_transform(affinity_matrix)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(X_diff_map)

    return labels

# Apply diffusion map spectral clustering with RBF affinity
labels_rbf = diffusion_map_spectral_clustering(X, n_clusters=10, affinity='rbf')
sampled_data['Diffusion Map Spectral Clustering (RBF)'] = labels_rbf

# Apply diffusion map spectral clustering with nearest neighbors affinity
labels_nn = diffusion_map_spectral_clustering(X, n_clusters=10, affinity='nearest_neighbors')
sampled_data['Diffusion Map Spectral Clustering (Nearest Neighbors)'] = labels_nn

# Function to evaluate the clustering results
def evaluate_clustering(X, labels, title):
    silhouette_avg = silhouette_score(X, labels)
    calinski_harabasz = calinski_harabasz_score(X, labels)
    davies_bouldin = davies_bouldin_score(X, labels)

    print(f"\n{title} Evaluation:")
    print(f"Silhouette Score: {silhouette_avg:.3f}")
    print(f"Calinski-Harabasz Score: {calinski_harabasz:.3f}")
    print(f"Davies-Bouldin Score: {davies_bouldin:.3f}")

# Function to map clusters to the most frequent genre/mood
def get_cluster_labels(labels, genre_labels, mood_labels, n_clusters=10):
    cluster_genre = []
    cluster_mood = []
    for cluster in range(n_clusters):
        mask = labels == cluster
        most_frequent_genre = genre_labels[mask].mode()[0]
        most_frequent_mood = mood_labels[mask].mode()[0]
        cluster_genre.append(most_frequent_genre)
        cluster_mood.append(most_frequent_mood)
    return cluster_genre, cluster_mood

# Plot function with aggregated cluster labels for genre and mood
def plot_tsne_with_color_labels(X_tsne_2d, labels, genre_labels, mood_labels, title):
    # Get the representative genre and mood labels for each cluster
    cluster_genre, cluster_mood = get_cluster_labels(labels, genre_labels, mood_labels)

    plt.figure(figsize=(12, 8))
    scatter = plt.scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], c=labels, cmap='Spectral', s=5)

    # Create a colorbar with the representative genre and mood for each cluster
    cbar = plt.colorbar(scatter, boundaries=np.arange(11)-0.5)
    cbar.set_ticks(np.arange(10))
    cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

    plt.title(f't-SNE 2D Visualization of {title}', fontsize=15)
    plt.xlabel("t-SNE Component 1")
    plt.ylabel("t-SNE Component 2")
    plt.show()

# Apply t-SNE for 2D visualization
tsne_2d = TSNE(n_components=2, perplexity=30, n_iter=300)
X_tsne_2d_rbf = tsne_2d.fit_transform(X)
X_tsne_2d_nn = tsne_2d.fit_transform(X)

# Use genre and mood labels from your dataset
genre_labels = sampled_data['track_genre']
mood_labels = sampled_data['mood']

# Evaluate Diffusion Map Spectral Clustering (RBF)
evaluate_clustering(X, labels_rbf, "Diffusion Map Spectral Clustering (RBF)")
# Plot t-SNE with aggregated genre and mood names for Diffusion Map Spectral Clustering (RBF)
plot_tsne_with_color_labels(X_tsne_2d_rbf, labels_rbf, genre_labels, mood_labels, "Diffusion Map Spectral Clustering (RBF)")

# Evaluate Diffusion Map Spectral Clustering (Nearest Neighbors)
evaluate_clustering(X, labels_nn, "Diffusion Map Spectral Clustering (Nearest Neighbors)")
# Plot t-SNE with aggregated genre and mood names for Diffusion Map Spectral Clustering (Nearest Neighbors)
plot_tsne_with_color_labels(X_tsne_2d_nn, labels_nn, genre_labels, mood_labels, "Diffusion Map Spectral Clustering (Nearest Neighbors)")

# Apply PCA after Diffusion Map Spectral Clustering
pca_2d = PCA(n_components=2)
X_pca_2d = pca_2d.fit_transform(X)

# Get the cluster labels (most frequent genre and mood per cluster)
cluster_genre, cluster_mood = get_cluster_labels(labels_rbf, genre_labels, mood_labels)

# 2D PCA Visualization for Diffusion Map Spectral Clustering
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1],
                      c=sampled_data['Diffusion Map Spectral Clustering (RBF)'], cmap='Spectral', s=50)
plt.title('PCA 2D Visualization - Diffusion Map Spectral Clustering (RBF)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')

# Create a colorbar with cluster genre and mood labels
cbar = plt.colorbar(scatter, ticks=np.arange(10))
cbar.set_label('Cluster Labels (Genre / Mood)')
cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

plt.show()

# For Diffusion Map Spectral Clustering
labels_diffusion = diffusion_map_spectral_clustering(X, n_clusters=10, affinity='rbf')
wcss_diffusion = calculate_wcss(X, labels_diffusion)
print(f"WCSS for the Diffusion Map Spectral Clustering (RBF): {wcss_diffusion}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.manifold import TSNE
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import rbf_kernel
from scipy.sparse import csgraph
from sklearn.decomposition import PCA
import pandas as pd
import plotly.express as px

# Assuming X and sampled_data are already loaded

def multiscale_spectral_clustering(X, n_clusters=10, affinity='rbf'):
    if affinity == 'rbf':
        # Use different gamma values for multiscale RBF kernel
        affinity_matrices = [rbf_kernel(X, gamma=gamma) for gamma in [0.1, 1, 10]]
    elif affinity == 'nearest_neighbors':
        affinity_matrices = []
        for gamma in [0.1, 1, 10]:
            neighbors = NearestNeighbors(n_neighbors=15).fit(X)
            affinity_matrices.append(neighbors.kneighbors_graph(X).toarray())

    # Combine the affinities by summing
    combined_affinity = sum(affinity_matrices)
    laplacian = csgraph.laplacian(combined_affinity, normed=True)

    # Eigen decomposition of the Laplacian
    eigenvalues, eigenvectors = np.linalg.eigh(laplacian)
    X_spec = eigenvectors[:, :n_clusters]
    X_spec_normalized = normalize(X_spec)

    # Apply K-Means on the normalized eigenvectors
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(X_spec_normalized)

    return labels

# Apply multiscale spectral clustering with RBF affinity
labels_rbf = multiscale_spectral_clustering(X, n_clusters=10, affinity='rbf')
sampled_data['Multiscale Spectral Clustering (RBF)'] = labels_rbf

# Apply multiscale spectral clustering with nearest neighbors affinity
labels_nn = multiscale_spectral_clustering(X, n_clusters=10, affinity='nearest_neighbors')
sampled_data['Multiscale Spectral Clustering (Nearest Neighbors)'] = labels_nn

# Function to evaluate clustering and visualize with t-SNE
def evaluate_clustering(X, labels, title):
    silhouette_avg = silhouette_score(X, labels)
    calinski_harabasz = calinski_harabasz_score(X, labels)
    davies_bouldin = davies_bouldin_score(X, labels)

    print(f"\n{title} Evaluation:")
    print(f"Silhouette Score: {silhouette_avg:.3f}")
    print(f"Calinski-Harabasz Score: {calinski_harabasz:.3f}")
    print(f"Davies-Bouldin Score: {davies_bouldin:.3f}")

# Function to map clusters to the most frequent genre/mood
def get_cluster_labels(labels, genre_labels, mood_labels, n_clusters=10):
    cluster_genre = []
    cluster_mood = []
    for cluster in range(n_clusters):
        mask = labels == cluster
        most_frequent_genre = genre_labels[mask].mode()[0]
        most_frequent_mood = mood_labels[mask].mode()[0]
        cluster_genre.append(most_frequent_genre)
        cluster_mood.append(most_frequent_mood)
    return cluster_genre, cluster_mood

# Plot function with aggregated cluster labels for genre and mood
def plot_tsne_with_color_labels(X_tsne_2d, labels, genre_labels, mood_labels, title):
    # Get the representative genre and mood labels for each cluster
    cluster_genre, cluster_mood = get_cluster_labels(labels, genre_labels, mood_labels)

    plt.figure(figsize=(12, 8))
    scatter = plt.scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], c=labels, cmap='Spectral', s=5)

    # Create a colorbar with the representative genre and mood for each cluster
    cbar = plt.colorbar(scatter, boundaries=np.arange(11)-0.5)
    cbar.set_ticks(np.arange(10))
    cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

    plt.title(f't-SNE 2D Visualization of {title}', fontsize=15)
    plt.xlabel("t-SNE Component 1")
    plt.ylabel("t-SNE Component 2")
    plt.show()

# Apply t-SNE for 2D visualization
tsne_2d = TSNE(n_components=2, perplexity=30, n_iter=300)
X_tsne_2d_rbf = tsne_2d.fit_transform(X)
X_tsne_2d_nn = tsne_2d.fit_transform(X)

# Use genre and mood labels from your dataset
genre_labels = sampled_data['track_genre']
mood_labels = sampled_data['mood']

# Evaluate Multiscale Spectral Clustering (RBF)
evaluate_clustering(X, labels_rbf, "Multiscale Spectral Clustering (RBF)")
# Plot t-SNE with aggregated genre and mood names for Multiscale Spectral Clustering (RBF)
plot_tsne_with_color_labels(X_tsne_2d_rbf, labels_rbf, genre_labels, mood_labels, "Multiscale Spectral Clustering (RBF)")

# Evaluate Multiscale Spectral Clustering (Nearest Neighbors)
evaluate_clustering(X, labels_nn, "Multiscale Spectral Clustering (Nearest Neighbors)")
# Plot t-SNE with aggregated genre and mood names for Multiscale Spectral Clustering (Nearest Neighbors)
plot_tsne_with_color_labels(X_tsne_2d_nn, labels_nn, genre_labels, mood_labels, "Multiscale Spectral Clustering (Nearest Neighbors)")

# Apply PCA after Multiscale Spectral Clustering
pca_2d = PCA(n_components=2)
X_pca_2d = pca_2d.fit_transform(X)

# Get the cluster labels (most frequent genre and mood per cluster)
cluster_genre, cluster_mood = get_cluster_labels(labels_rbf, genre_labels, mood_labels)

# 2D PCA Visualization for Multiscale Spectral Clustering
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1],
                      c=sampled_data['Multiscale Spectral Clustering (RBF)'], cmap='Spectral', s=50)
plt.title('PCA 2D Visualization - Multiscale Spectral Clustering (RBF)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')

# Create a colorbar with cluster genre and mood labels
cbar = plt.colorbar(scatter, ticks=np.arange(10))
cbar.set_label('Cluster Labels (Genre / Mood)')
cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

plt.show()

# For Multiscale Spectral Clustering
labels_multiscale = multiscale_spectral_clustering(X, n_clusters=10, affinity='rbf')
wcss_multiscale = calculate_wcss(X, labels_multiscale)
print(f"WCSS for the Multiscale Spectral Clustering (RBF): {wcss_multiscale}")

# Impute missing values with the mean of the column
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
from sklearn.metrics.pairwise import polynomial_kernel, sigmoid_kernel
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.impute import SimpleImputer
from scipy.linalg import eigh
from scipy.sparse import csgraph
from sklearn.manifold import TSNE
import plotly.express as px
import pandas as pd

# Function for Kernel Spectral Clustering with Additional Validation Checks
def kernel_spectral_clustering(X, n_clusters=10, kernel='polynomial', regularization=1e-6):
    # Compute the affinity matrix using the selected kernel
    if kernel == 'polynomial':
        affinity_matrix = polynomial_kernel(X, degree=3, gamma=1.0)
    elif kernel == 'sigmoid':
        affinity_matrix = sigmoid_kernel(X, gamma=1.0, coef0=1.0)

    # Add a small regularization term to the diagonal of the affinity matrix
    np.fill_diagonal(affinity_matrix, affinity_matrix.diagonal() + regularization)

    # Check and clean the affinity matrix for NaN or infinite values
    if np.isnan(affinity_matrix).any() or np.isinf(affinity_matrix).any():
        print("Affinity matrix contains NaN or infinite values. Cleaning the matrix...")
        affinity_matrix = np.nan_to_num(affinity_matrix, nan=0.0, posinf=1e10, neginf=-1e10)

    # Compute the Laplacian matrix
    laplacian = csgraph.laplacian(affinity_matrix, normed=True)

    # Check for NaNs or infinite values in the Laplacian
    if np.isnan(laplacian).any() or np.isinf(laplacian).any():
        print("Laplacian matrix contains NaN or infinite values.")
        return None

    # Eigen decomposition using scipy.linalg.eigh (more robust)
    eigenvalues, eigenvectors = eigh(laplacian)
    X_kernel = eigenvectors[:, :n_clusters]

    # Apply KMeans
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(X_kernel)

    return labels

# Impute missing values with the mean of the column
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# Verify that there are no NaN or infinite values left after imputation
if np.isnan(X_imputed).any() or np.isinf(X_imputed).any():
    raise ValueError("Imputed data contains NaN or infinite values.")

# Perform Kernel Spectral Clustering using a polynomial kernel
labels_kernel_poly = kernel_spectral_clustering(X_imputed, n_clusters=10, kernel='polynomial', regularization=1e-6)

if labels_kernel_poly is not None:
    sampled_data['Kernel Spectral Clustering (Polynomial)'] = labels_kernel_poly

    # Function to map clusters to the most frequent genre/mood
    def get_cluster_labels(labels, genre_labels, mood_labels, n_clusters=10):
        cluster_genre = []
        cluster_mood = []
        for cluster in range(n_clusters):
            mask = labels == cluster
            most_frequent_genre = genre_labels[mask].mode()[0]
            most_frequent_mood = mood_labels[mask].mode()[0]
            cluster_genre.append(most_frequent_genre)
            cluster_mood.append(most_frequent_mood)
        return cluster_genre, cluster_mood

    # Plot function with aggregated cluster labels for genre and mood
    def plot_tsne_with_color_labels(X_tsne_2d, labels, genre_labels, mood_labels, title):
        # Get the representative genre and mood labels for each cluster
        cluster_genre, cluster_mood = get_cluster_labels(labels, genre_labels, mood_labels)

        plt.figure(figsize=(12, 8))
        scatter = plt.scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], c=labels, cmap='Spectral', s=5)

        # Create a colorbar with the representative genre and mood for each cluster
        cbar = plt.colorbar(scatter, boundaries=np.arange(11)-0.5)
        cbar.set_ticks(np.arange(10))
        cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

        plt.title(f't-SNE 2D Visualization of {title}', fontsize=15)
        plt.xlabel("t-SNE Component 1")
        plt.ylabel("t-SNE Component 2")
        plt.show()

    # Apply t-SNE for 2D visualization
    tsne_2d = TSNE(n_components=2, perplexity=30, n_iter=300)
    X_tsne_2d = tsne_2d.fit_transform(X_imputed)

    # Use genre and mood labels from your dataset
    genre_labels = sampled_data['track_genre']
    mood_labels = sampled_data['mood']

    # Evaluate Kernel Spectral Clustering (Polynomial)
    def evaluate_clustering(X, labels, title):
        silhouette_avg = silhouette_score(X, labels)
        calinski_harabasz = calinski_harabasz_score(X, labels)
        davies_bouldin = davies_bouldin_score(X, labels)

        print(f"\n{title} Evaluation:")
        print(f"Silhouette Score: {silhouette_avg:.3f}")
        print(f"Calinski-Harabasz Score: {calinski_harabasz:.3f}")
        print(f"Davies-Bouldin Score: {davies_bouldin:.3f}")

        # Apply t-SNE for 2D visualization with genre/mood labels
        plot_tsne_with_color_labels(X_tsne_2d, labels, genre_labels, mood_labels, title)

    # Evaluate and visualize the clustering
    evaluate_clustering(X_imputed, labels_kernel_poly, "Kernel Spectral Clustering (Polynomial)")

    # Apply PCA for additional visualization
    pca_2d = PCA(n_components=2)
    X_pca_2d = pca_2d.fit_transform(X_imputed)

    # Get the cluster labels (most frequent genre and mood per cluster)
    cluster_genre, cluster_mood = get_cluster_labels(labels_kernel_poly, genre_labels, mood_labels)

    # 2D PCA Visualization for Kernel Spectral Clustering
    plt.figure(figsize=(10, 7))
    scatter = plt.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1],
                          c=sampled_data['Kernel Spectral Clustering (Polynomial)'], cmap='Spectral', s=50)
    plt.title('PCA 2D Visualization - Kernel Spectral Clustering (Polynomial)')
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')

    # Create a colorbar with cluster genre and mood labels
    cbar = plt.colorbar(scatter, ticks=np.arange(10))
    cbar.set_label('Cluster Labels (Genre / Mood)')
    cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

    plt.show()

else:
    print("Clustering was not performed due to invalid Laplacian matrix.")

wcss_kernel = calculate_wcss(X, labels_kernel_poly)
print(f"WCSS for the Kernel Spectral Clustering (Polynomial): {wcss_kernel}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import normalize
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.manifold import TSNE
from sklearn.neighbors import NearestNeighbors
from sklearn.metrics.pairwise import rbf_kernel
from scipy.sparse import csgraph
from sklearn.decomposition import PCA
import plotly.express as px

# Laplacian Eigenmaps Spectral Clustering
def laplacian_eigenmaps_spectral_clustering(X, n_clusters=10, affinity='rbf'):
    if affinity == 'rbf':
        affinity_matrix = rbf_kernel(X, gamma=1.0)
    elif affinity == 'nearest_neighbors':
        neighbors = NearestNeighbors(n_neighbors=15).fit(X)
        affinity_matrix = neighbors.kneighbors_graph(X).toarray()

    laplacian = csgraph.laplacian(affinity_matrix, normed=False)
    eigenvalues, eigenvectors = np.linalg.eigh(laplacian)
    X_laplacian = eigenvectors[:, :n_clusters]

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(X_laplacian)

    return labels

# Apply Laplacian Eigenmaps Spectral Clustering
labels_laplacian = laplacian_eigenmaps_spectral_clustering(X, n_clusters=10, affinity='rbf')
sampled_data['Laplacian Eigenmaps Spectral Clustering (RBF)'] = labels_laplacian

# Function to map clusters to the most frequent genre/mood
def get_cluster_labels(labels, genre_labels, mood_labels, n_clusters=10):
    cluster_genre = []
    cluster_mood = []
    for cluster in range(n_clusters):
        mask = labels == cluster
        most_frequent_genre = genre_labels[mask].mode()[0]
        most_frequent_mood = mood_labels[mask].mode()[0]
        cluster_genre.append(most_frequent_genre)
        cluster_mood.append(most_frequent_mood)
    return cluster_genre, cluster_mood

# Plot function with aggregated cluster labels for genre and mood
def plot_tsne_with_color_labels(X_tsne_2d, labels, genre_labels, mood_labels, title):
    # Get the representative genre and mood labels for each cluster
    cluster_genre, cluster_mood = get_cluster_labels(labels, genre_labels, mood_labels)

    plt.figure(figsize=(12, 8))
    scatter = plt.scatter(X_tsne_2d[:, 0], X_tsne_2d[:, 1], c=labels, cmap='Spectral', s=5)

    # Create a colorbar with the representative genre and mood for each cluster
    cbar = plt.colorbar(scatter, boundaries=np.arange(11)-0.5)
    cbar.set_ticks(np.arange(10))
    cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

    plt.title(f't-SNE 2D Visualization of {title}', fontsize=15)
    plt.xlabel("t-SNE Component 1")
    plt.ylabel("t-SNE Component 2")
    plt.show()

# Apply t-SNE for 2D visualization
tsne_2d = TSNE(n_components=2, perplexity=30, n_iter=300)
X_tsne_2d = tsne_2d.fit_transform(X)

# Use genre and mood labels from your dataset
genre_labels = sampled_data['track_genre']
mood_labels = sampled_data['mood']

# Evaluation and Visualization
def evaluate_clustering(X, labels, title):
    silhouette_avg = silhouette_score(X, labels)
    calinski_harabasz = calinski_harabasz_score(X, labels)
    davies_bouldin = davies_bouldin_score(X, labels)

    print(f"\n{title} Evaluation:")
    print(f"Silhouette Score: {silhouette_avg:.3f}")
    print(f"Calinski-Harabasz Score: {calinski_harabasz:.3f}")
    print(f"Davies-Bouldin Score: {davies_bouldin:.3f}")

    # Apply t-SNE for 2D visualization with genre/mood labels
    plot_tsne_with_color_labels(X_tsne_2d, labels, genre_labels, mood_labels, title)



# Evaluate Laplacian Eigenmaps Spectral Clustering (RBF)
evaluate_clustering(X, labels_laplacian, "Laplacian Eigenmaps Spectral Clustering (RBF)")

# Apply PCA after Laplacian Eigenmaps Spectral Clustering
pca_2d = PCA(n_components=2)
X_pca_2d = pca_2d.fit_transform(X)

# Get the cluster labels (most frequent genre and mood per cluster)
cluster_genre, cluster_mood = get_cluster_labels(labels_laplacian, genre_labels, mood_labels)

# 2D PCA Visualization for Laplacian Eigenmaps Spectral Clustering
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_pca_2d[:, 0], X_pca_2d[:, 1],
                      c=sampled_data['Laplacian Eigenmaps Spectral Clustering (RBF)'], cmap='Spectral', s=50)
plt.title('PCA 2D Visualization - Laplacian Eigenmaps Spectral Clustering (RBF)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')

# Create a colorbar with cluster genre and mood labels
cbar = plt.colorbar(scatter, ticks=np.arange(10))
cbar.set_label('Cluster Labels (Genre / Mood)')
cbar.set_ticklabels([f'{g} / {m}' for g, m in zip(cluster_genre, cluster_mood)])

plt.show()

wcss_laplacian = calculate_wcss(X, labels_laplacian)
print(f"WCSS for the Laplacian Eigenmaps Spectral Clustering (RBF): {wcss_laplacian}")

# Initialize a dictionary to store the evaluation metrics
evaluation_results = {}
from sklearn.preprocessing import StandardScaler


# Standardize the feature matrix
scaler = StandardScaler()
X_standardized = scaler.fit_transform(X)


# Define a function to store and print evaluation results
def store_and_print_results(method_name, silhouette, calinski_harabasz, davies_bouldin):
    evaluation_results[method_name] = {
        'Silhouette Score': silhouette,
        'Calinski-Harabasz Score': calinski_harabasz,
        'Davies-Bouldin Score': davies_bouldin
    }

    print(f"\n{method_name} Performance:")
    print(f"Silhouette Score: {silhouette:.3f}")
    print(f"Calinski-Harasz Score: {calinski_harabasz:.3f}")
    print(f"Davies-Bouldin Score: {davies_bouldin:.3f}")

# Evaluate all methods and store results
for method in ['Normalized', 'Unnormalized', 'Diffusion Map', 'Multiscale', 'Kernel', 'Laplacian']:
    if method in ['Normalized', 'Unnormalized', 'Diffusion Map', 'Multiscale']:
        for affinity in ['RBF', 'Nearest Neighbors']:
            method_name = f"{method} Spectral Clustering ({affinity})"
            if method_name in sampled_data.columns:
                labels = sampled_data[method_name]

                # Calculate evaluation metrics
                silhouette = silhouette_score(X_standardized, labels)
                calinski_harabasz = calinski_harabasz_score(X_standardized, labels)
                davies_bouldin = davies_bouldin_score(X_standardized, labels)

                # Store and print results
                store_and_print_results(method_name, silhouette, calinski_harabasz, davies_bouldin)

    elif method == 'Kernel':
        for kernel_type in ['Polynomial']:
            method_name = f"{method} Spectral Clustering ({kernel_type})"
            if method_name in sampled_data.columns:
                labels = sampled_data[method_name]

                # Calculate evaluation metrics
                silhouette = silhouette_score(X_standardized, labels)
                calinski_harabasz = calinski_harabasz_score(X_standardized, labels)
                davies_bouldin = davies_bouldin_score(X_standardized, labels)

                # Store and print results
                store_and_print_results(method_name, silhouette, calinski_harabasz, davies_bouldin)

    elif method == 'Laplacian':
        method_name = "Laplacian Eigenmaps Spectral Clustering (RBF)"
        if method_name in sampled_data.columns:
            labels = sampled_data[method_name]

            # Calculate evaluation metrics
            silhouette = silhouette_score(X_standardized, labels)
            calinski_harabasz = calinski_harabasz_score(X_standardized, labels)
            davies_bouldin = davies_bouldin_score(X_standardized, labels)

            # Store and print results
            store_and_print_results(method_name, silhouette, calinski_harabasz, davies_bouldin)

# Summarize and compare results
print("\nSummary of Clustering Algorithm Performance:")
summary_df = pd.DataFrame(evaluation_results).T
summary_df = summary_df.sort_values(by="Silhouette Score", ascending=False)
print(summary_df)

# Visualize the comparison of Silhouette Scores across different methods
plt.figure(figsize=(12, 6))
summary_df['Silhouette Score'].plot(kind='bar', color='skyblue')
plt.title("Comparison of Silhouette Scores across Spectral Clustering Methods")
plt.ylabel("Silhouette Score")
plt.xticks(rotation=45, ha="right")
plt.show()

# Visualize the comparison of Calinski-Harabasz Scores across different methods
plt.figure(figsize=(12, 6))
summary_df['Calinski-Harabasz Score'].plot(kind='bar', color='lightgreen')
plt.title("Comparison of Calinski-Harabasz Scores across Spectral Clustering Methods")
plt.ylabel("Calinski-Harabasz Score")
plt.xticks(rotation=45, ha="right")
plt.show()

# Visualize the comparison of Davies-Bouldin Scores across different methods
plt.figure(figsize=(12, 6))
summary_df['Davies-Bouldin Score'].plot(kind='bar', color='salmon')
plt.title("Comparison of Davies-Bouldin Scores across Spectral Clustering Methods")
plt.ylabel("Davies-Bouldin Score")
plt.xticks(rotation=45, ha="right")
plt.show()

# Determine the best method based on Silhouette Score
best_method = summary_df.idxmax()['Silhouette Score']
best_silhouette = summary_df.loc[best_method]['Silhouette Score']
print(f"\nBest Method based on Silhouette Score: {best_method} with Silhouette Score: {best_silhouette:.3f}")

# Determine the best method based on Calinski-Harabasz Score
best_ch = summary_df.idxmax()['Calinski-Harabasz Score']
best_calinski = summary_df.loc[best_ch]['Calinski-Harabasz Score']
print(f"Best Method based on Calinski-Harabasz Score: {best_ch} with Calinski-Harabasz Score: {best_calinski:.3f}")

# Determine the best method based on Davies-Bouldin Score (lower is better)
best_db = summary_df.idxmin()['Davies-Bouldin Score']
best_davies_bouldin = summary_df.loc[best_db]['Davies-Bouldin Score']
print(f"Best Method based on Davies-Bouldin Score: {best_db} with Davies-Bouldin Score: {best_davies_bouldin:.3f}")

# Debugging: Print the structure of evaluation_results before iteration
print("\nDebugging: Contents of evaluation_results")
print(evaluation_results)

import matplotlib.pyplot as plt
import pandas as pd

# Data (based on the provided output values)
evaluation_metrics = {
    "Method": [
        "Normalized Spectral (RBF)",
        "Normalized Spectral (Nearest Neighbors)",
        "Unnormalized Spectral (RBF)",
        "Unnormalized Spectral (Nearest Neighbors)",
        "Diffusion Map Spectral (RBF)",
        "Diffusion Map Spectral (Nearest Neighbors)",
        "Multiscale Spectral (RBF)",
        "Multiscale Spectral (Nearest Neighbors)",
        "Kernel Spectral (Polynomial)"
    ],
    "Silhouette Score": [
        0.164, -0.090, -0.040, -0.292, 0.129, -0.005, 0.161, -0.043, 0.143
    ],
    "Calinski-Harabasz Score": [
        613.981, 224.644, 5.324, 20.707, 380.432, 337.309, 586.611, 254.380, 528.724
    ],
    "Davies-Bouldin Score": [
        1.622, 2.494, 0.678, 1.228, 1.215, 1.274, 1.459, 2.685, 1.466
    ]
}

# Convert to DataFrame
df_evaluation_metrics = pd.DataFrame(evaluation_metrics)

# Plot Silhouette and Calinski-Harabasz Scores on the same plot with different y-axes
fig, ax1 = plt.subplots(figsize=(14, 8))

# First plot with Silhouette Score
color1 = 'tab:blue'
ax1.set_xlabel('Clustering Method')
ax1.set_ylabel('Silhouette Score', color=color1)
ax1.plot(df_evaluation_metrics['Method'], df_evaluation_metrics['Silhouette Score'], marker='o', color=color1, label='Silhouette Score')
ax1.tick_params(axis='y', labelcolor=color1)
ax1.set_xticklabels(df_evaluation_metrics['Method'], rotation=45, ha="right")

# Second y-axis for Calinski-Harabasz Score
ax2 = ax1.twinx()
color2 = 'tab:green'
ax2.set_ylabel('Calinski-Harabasz Score', color=color2)
ax2.plot(df_evaluation_metrics['Method'], df_evaluation_metrics['Calinski-Harabasz Score'], marker='o', color=color2, label='Calinski-Harabasz Score')
ax2.tick_params(axis='y', labelcolor=color2)

fig.tight_layout()
plt.show()

# Plot Davies-Bouldin Score separately
fig, ax3 = plt.subplots(figsize=(14, 6))
color3 = 'tab:red'
ax3.set_xlabel('Clustering Method')
ax3.set_ylabel('Davies-Bouldin Score', color=color3)
ax3.plot(df_evaluation_metrics['Method'], df_evaluation_metrics['Davies-Bouldin Score'], marker='o', color=color3, label='Davies-Bouldin Score')
ax3.tick_params(axis='y', labelcolor=color3)
ax3.set_xticklabels(df_evaluation_metrics['Method'], rotation=45, ha="right")

plt.tight_layout()
plt.show()

# Explanation on why Kernel Spectral Clustering (Polynomial) is preferred based on your results
print(f"\nIn the context of the dataset, Normalized Spectral Clustering (RBF) is particularly effective because it handles non-linear relationships well, which are likely present in music data due to the complex interplay of various audio features. This makes it an ideal choice for clustering genres and moods effectively.\n")

# Step 4: Apply K-Means clustering to the audio features and map clusters to moods
kmeans = KMeans(n_clusters=10, random_state=42)  # 10 clusters for different moods
sampled_data['cluster'] = kmeans.fit_predict(sampled_data[audio_features])

# Map each cluster to a corresponding mood label
mood_map = {0: 'Happy', 1: 'Sad', 2: 'Energetic', 3: 'Calm', 4: 'Romantic',
            5: 'Aggressive', 6: 'Melancholic', 7: 'Uplifting', 8: 'Chill', 9: 'Party'}
sampled_data['mood'] = sampled_data['cluster'].map(mood_map)
# Add the best clustering labels to the dataset
sampled_data['best_cluster'] = sampled_data['Normalized Spectral Clustering (RBF)']#####
# Save the modified dataset with the new 'mood' column to Google Drive
output_path = '/content/drive/MyDrive/dataset_with_mood_clusters.csv'
sampled_data.to_csv(output_path, index=False)

"""# Model Training"""

# Step 5: Reload the dataset and encode categorical features
sampled_data = pd.read_csv(output_path)

# Encode the 'track_genre' and 'mood' columns to numerical values for machine learning models
label_encoder_genre = LabelEncoder()
sampled_data['genre_encoded'] = label_encoder_genre.fit_transform(sampled_data['track_genre'])

label_encoder_mood = LabelEncoder()
sampled_data['mood_encoded'] = label_encoder_mood.fit_transform(sampled_data['mood'])

# Split the dataset into training and testing sets for both genre and mood prediction
X = sampled_data[audio_features + ['best_cluster']]######
y_genre =sampled_data['genre_encoded']
y_mood = sampled_data['mood_encoded']

X_train, X_test, y_train_genre, y_test_genre = train_test_split(X, y_genre, test_size=0.2,random_state=42)
X_train_mood, X_test_mood, y_train_mood, y_test_mood = train_test_split(X, y_mood, test_size=0.2,  random_state=42)

"""# Model Approach : Gradiant Boosting and Voting Classifier"""

#  Train ensemble models for genre and mood prediction
# Hyperparameter tuning for Random Forest
param_grid = {'n_estimators': [100, 200], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5]}
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train_genre)
best_genre_model = grid_search.best_estimator_

# Gradient Boosting for mood prediction
mood_model = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, random_state=42)
mood_model.fit(X_train_mood, y_train_mood)

# Ensemble model combining both approaches
ensemble_model = VotingClassifier(estimators=[('rf', best_genre_model), ('gb', mood_model)], voting='soft')
ensemble_model.fit(X_train, y_train_genre)

# Split the dataset into training and testing sets for both genre and mood prediction
X_train, X_test, y_train_genre, y_test_genre = train_test_split(X, y_genre, test_size=0.2, random_state=42)
X_train_mood, X_test_mood, y_train_mood, y_test_mood = train_test_split(X, y_mood, test_size=0.2, random_state=42)

# Insert this snippet after the train-test split
print("Shape of X_test:", X_test.shape)
print("Shape of y_test_genre:", y_test_genre.shape)

y_pred_genre = best_genre_model.predict(X_test)
print("Shape of y_pred_genre:", y_pred_genre.shape)

if len(y_test_genre) != len(y_pred_genre):
    print(f"Inconsistent number of samples: y_test_genre = {len(y_test_genre)}, y_pred_genre = {len(y_pred_genre)}")

if len(y_test_genre) == len(y_pred_genre):
    print("Genre Classification Report:")
    print(classification_report(y_test_genre, y_pred_genre))
else:
    print("Error: Mismatch in the number of samples between y_test_genre and y_pred_genre.")

"""# # Model Testing and Evaluation"""

# Step 7: Evaluate the genre prediction model
y_pred_genre = best_genre_model.predict(X_test)
print("Genre Classification Report:")
print(classification_report(y_test_genre, y_pred_genre))

# Visualize the confusion matrix for the genre prediction model
cm_genre = confusion_matrix(y_test_genre, y_pred_genre)

# Align the labels with the classes present in the confusion matrix
unique_labels = sorted(set(y_test_genre).union(set(y_pred_genre)))

# Update the display_labels to reflect only the unique labels in the test set
disp_genre = ConfusionMatrixDisplay(confusion_matrix=cm_genre, display_labels=label_encoder_genre.inverse_transform(unique_labels))
disp_genre.plot(cmap=plt.cm.Blues)
# Fix the x-axis label clutter by rotating the labels and adjusting the layout
plt.xticks(rotation=90)  # Rotate the x-axis labels by 90 degrees
plt.tight_layout()
plt.title("Genre Classification Confusion Matrix")
plt.show()

"""# 1-Models Approach :  Implementing Spectral Clustering Algorithms

# Training and testing of Spectral Clustering Algorithms
"""

import numpy as np
from sklearn.cluster import SpectralClustering
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics.pairwise import cosine_similarity, rbf_kernel
from sklearn.neighbors import kneighbors_graph
from scipy.linalg import eigh

# Step 1: Data Preprocessing
label_encoder_genre = LabelEncoder()
label_encoder_mood = LabelEncoder()

# Encode labels for genre and mood
y_genre = label_encoder_genre.fit_transform(y_genre)
y_mood = label_encoder_mood.fit_transform(y_mood)

# Standardize the feature set
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# PCA with 5 Components to retain more information and remove noise
pca = PCA(n_components=5)
X_pca = pca.fit_transform(X_scaled)

# Handle NaNs or Infs in the data
X_pca = np.nan_to_num(X_pca)

# Step 2: Construct the Weighted Graph (Symmetric Similarity Matrix)
def build_weighted_graph(X, features, threshold=0.05):
    """
    Constructs a weighted symmetric similarity matrix representing an edge-weighted graph of songs.
    The edge weights are based on the number of features (liveness, danceability, energy) where the values are within 0.1 of each other.
    """
    n = X.shape[0]
    weighted_similarity_matrix = np.zeros((n, n))

    for i in range(n):
        for j in range(i, n):
            # Define the weight as the sum of similar features between song i and song j
            weight = np.sum(np.abs(features[i] - features[j]) < threshold)
            weighted_similarity_matrix[i, j] = weight
            weighted_similarity_matrix[j, i] = weight  # Ensure symmetry

    return weighted_similarity_matrix

# Use selected features like liveness, danceability, energy for the weighted graph
selected_features = X_scaled
weighted_similarity_matrix = build_weighted_graph(X_scaled, selected_features, threshold=0.05)

# Step 3: Eigenvalue Analysis for Spectral Clustering
def eigenvalue_analysis(similarity_matrix):
    """
    Performs eigenvalue and eigenvector analysis on the similarity matrix.
    Returns eigenvalues and eigenvectors.
    """
    eigenvalues, eigenvectors = eigh(similarity_matrix)

    # Sort eigenvalues and eigenvectors in descending order of eigenvalues
    idx = np.argsort(eigenvalues)[::-1]
    eigenvalues = eigenvalues[idx]
    eigenvectors = eigenvectors[:, idx]

    print("Eigenvalue analysis:")
    print("Top 5 Eigenvalues: ", eigenvalues[:5])  # Output top 5 eigenvalues for analysis

    return eigenvalues, eigenvectors

# Perform eigenvalue analysis
eigenvalues, eigenvectors = eigenvalue_analysis(weighted_similarity_matrix)

# Step 4: Spectral Clustering and Classification (Reusable Function for All Methods)
def spectral_clustering_and_classify(X, y_genre, y_mood, n_clusters, method_name,
                                     affinity='precomputed', similarity_matrix=None):
    """
    Performs spectral clustering using the weighted graph, evaluates clustering quality, and trains classifiers for genre and mood.
    """
    random_state = np.random.randint(0, 10000)

    # Apply Spectral Clustering using the weighted similarity matrix
    clustering = SpectralClustering(
        n_clusters=n_clusters, affinity=affinity,
        assign_labels='discretize', random_state=random_state)
    labels = clustering.fit_predict(similarity_matrix)

    # Evaluate clustering quality
    silhouette_avg = silhouette_score(X, labels)
    calinski_harabasz = calinski_harabasz_score(X, labels)
    davies_bouldin = davies_bouldin_score(X, labels)

    print(f"\n{method_name} with {n_clusters} clusters (Weighted Graph):")
    print(f"Silhouette Score: {silhouette_avg:.4f}")
    print(f"Calinski-Harabasz Score: {calinski_harabasz:.4f}")
    print(f"Davies-Bouldin Score: {davies_bouldin:.4f}")

    # Classification Task
    X_with_clusters = np.hstack((X, labels.reshape(-1, 1)))
    X_train_genre, X_test_genre, y_train_genre, y_test_genre = train_test_split(
        X_with_clusters, y_genre, test_size=0.2, random_state=random_state)

    X_train_mood, X_test_mood, y_train_mood, y_test_mood = train_test_split(
        X_with_clusters, y_mood, test_size=0.2, random_state=random_state)

    # Random Forest for Genre Prediction
    rf_genre = RandomForestClassifier(n_estimators=1000, random_state=random_state, n_jobs=-1)
    rf_genre.fit(X_train_genre, y_train_genre)

    # Gradient Boosting for Mood Prediction
    gb_mood = GradientBoostingClassifier(n_estimators=1000, random_state=random_state)
    gb_mood.fit(X_train_mood, y_train_mood)

    # Predict genre and mood
    y_pred_genre = rf_genre.predict(X_test_genre)
    y_pred_mood = gb_mood.predict(X_test_mood)

    # Print classification reports
    print(f"\n{method_name} - Genre Classification Report:")
    print(classification_report(y_test_genre, y_pred_genre))

    print(f"\n{method_name} - Mood Classification Report:")
    print(classification_report(y_test_mood, y_pred_mood))

# Step 5: Apply Various Spectral Clustering Methods (Using Precomputed Affinity for All)

n_clusters = 3

# 1. Normalized Spectral Clustering (Best Affinity: RBF Kernel)
rbf_affinity = rbf_kernel(X_scaled, gamma=1.0)
spectral_clustering_and_classify(
    X_scaled, y_genre, y_mood, n_clusters,
    "Normalized Spectral Clustering", affinity='precomputed',
    similarity_matrix=rbf_affinity)


# 2. Unnormalized Spectral Clustering (Using Same Affinity)
spectral_clustering_and_classify(
    X_scaled, y_genre, y_mood, n_clusters,
    "Unnormalized Spectral Clustering", affinity='precomputed',
    similarity_matrix=weighted_similarity_matrix)

# 3. Multiscale Spectral Clustering (using RBF kernel with different gamma values)
gamma_values = [0.1, 1, 10]
affinity_matrices = [rbf_kernel(X_scaled, gamma=gamma) for gamma in gamma_values]
combined_affinity = sum(affinity_matrices)
spectral_clustering_and_classify(
    X_scaled, y_genre, y_mood, n_clusters,
    "Multiscale Spectral Clustering", affinity='precomputed',
    similarity_matrix=combined_affinity)

# 4. Kernel Spectral Clustering (polynomial kernel)
affinity_matrix_kernel = (X_scaled @ X_scaled.T) ** 2
spectral_clustering_and_classify(
    X_scaled, y_genre, y_mood, n_clusters,
    "Kernel Spectral Clustering", affinity='precomputed',
    similarity_matrix=affinity_matrix_kernel)

# 5. Laplacian Eigenmaps Spectral Clustering (k-nearest neighbors graph)
X_laplacian_affinity = kneighbors_graph(X_scaled, n_neighbors=10, include_self=True).toarray()
X_laplacian_affinity = np.nan_to_num(X_laplacian_affinity)  # Ensure no NaNs are passed
spectral_clustering_and_classify(
    X_scaled, y_genre, y_mood, n_clusters,
    "Laplacian Eigenmaps Spectral Clustering", affinity='precomputed',
    similarity_matrix=X_laplacian_affinity)

# 6. Diffusion Maps Spectral Clustering
spectral_clustering_and_classify(
    X_scaled, y_genre, y_mood, n_clusters,
    "Diffusion Maps Spectral Clustering", affinity='precomputed',
    similarity_matrix=weighted_similarity_matrix)

# Step 3: Visualize clustering metrics (Silhouette Score, Genre Accuracy, Mood Accuracy)
methods = [
    "Normalized SC",
    "Unnormalized SC",
    "Multiscale SC",
    "Kernel SC",
    "Laplacian SC",
    "Diffusion SC",
]
# Updated silhouette scores based on your output
silhouette_scores = [0.2174,0.1404,0.2375, 0.0204,0.1579,0.1402]

# Updated genre classification accuracy based on your output
genre_accuracy = [0.62,0.63,0.60,0.63,0.59,0.62]

# Updated mood classification accuracy based on your output
mood_accuracy = [0.95,0.92, 0.94, 0.93, 0.93, 0.95]


# Plot comparison of clustering algorithms
plt.figure(figsize=(14, 7))
plt.plot(
    methods,
    silhouette_scores,
    marker='o',
    label='Silhouette Score',
    color='dodgerblue',
    linewidth=2,
    markersize=8,
)
plt.plot(
    methods,
    genre_accuracy,
    marker='s',
    label='Genre Accuracy',
    color='darkorange',
    linewidth=2,
    markersize=8,
)
plt.plot(
    methods,
    mood_accuracy,
    marker='^',
    label='Mood Accuracy',
    color='forestgreen',
    linewidth=2,
    markersize=8,
)
plt.title('Comparison of Spectral Clustering Algorithms', fontsize=16, fontweight='bold')
plt.xlabel('Clustering Method', fontsize=14)
plt.ylabel('Score/Accuracy', fontsize=14)
plt.grid(True, which='both', linestyle='--', linewidth=0.6, alpha=0.7)
plt.legend(fontsize=12)
plt.xticks(fontsize=12, rotation=45)
plt.yticks(fontsize=12)
plt.tight_layout()
plt.show()

# Bar plot visualization
bar_width = 0.25
index = np.arange(len(methods))
plt.figure(figsize=(14, 7))
plt.bar(
    index,
    silhouette_scores,
    bar_width,
    label='Silhouette Score',
    color='dodgerblue',
)
plt.bar(
    index + bar_width,
    genre_accuracy,
    bar_width,
    label='Genre Accuracy',
    color='darkorange',
)
plt.bar(
    index + 2 * bar_width,
    mood_accuracy,
    bar_width,
    label='Mood Accuracy',
    color='forestgreen',
)
plt.title('Comparison of Spectral Clustering Algorithms', fontsize=16, fontweight='bold')
plt.xlabel('Clustering Method', fontsize=14)
plt.ylabel('Score/Accuracy', fontsize=14)
plt.xticks(index + bar_width, methods, fontsize=12, rotation=45)
plt.yticks(fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, which='both', linestyle='--', linewidth=0.6, alpha=0.7)
plt.tight_layout()
plt.show()

"""#3- Model Approach: Random Forest Classifier with Cross Validation

# Model testing and Evaluation
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score
import matplotlib.pyplot as plt
import numpy as np

# Ensure the label encoders are initialized
label_encoder_genre = LabelEncoder()
sampled_data['genre_encoded'] = label_encoder_genre.fit_transform(sampled_data['track_genre'])

label_encoder_mood = LabelEncoder()
sampled_data['mood_encoded'] = label_encoder_mood.fit_transform(sampled_data['mood'])

# Features and targets for genre prediction
X = sampled_data[audio_features + ['best_cluster']]  # 'best_cluster' from the best method in Step 12
y_genre = sampled_data['genre_encoded']

# Split the dataset into training and testing sets
X_train_genre, X_test_genre, y_train_genre, y_test_genre = train_test_split(X, y_genre, test_size=0.6, random_state=42)

# Step 8: Define a Random Forest model
rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)

# Step 9: Train the model and evaluate
rf_model.fit(X_train_genre, y_train_genre)
y_pred_genre = rf_model.predict(X_test_genre)

# Step 10: Print out the classification report and plot the confusion matrix
print("Classification Report - Genre Prediction:")
print(classification_report(y_test_genre, y_pred_genre, target_names=label_encoder_genre.classes_))

# Confusion Matrix for Genre Prediction
cm_genre = confusion_matrix(y_test_genre, y_pred_genre)
disp_genre = ConfusionMatrixDisplay(confusion_matrix=cm_genre, display_labels=label_encoder_genre.classes_)
disp_genre.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=90)
plt.title("Confusion Matrix - Random Forest Genre Prediction")
plt.show()

# Step 11: Plot feature importance
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]
plt.figure()
plt.title("Feature Importances")
plt.bar(range(X_train_genre.shape[1]), importances[indices], color="r", align="center")
plt.xticks(range(X_train_genre.shape[1]), [X.columns[i] for i in indices], rotation=90)
plt.xlim([-1, X_train_genre.shape[1]])
plt.show()

# Step 12: Evaluate additional metrics
print(f"F1-Score: {f1_score(y_test_genre, y_pred_genre, average='weighted'):.4f}")
print(f"Precision: {precision_score(y_test_genre, y_pred_genre, average='weighted'):.4f}")
print(f"Recall: {recall_score(y_test_genre, y_pred_genre, average='weighted'):.4f}")

# Step 13: K-Fold Cross-Validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(rf_model, X, y_genre, cv=kf, scoring='accuracy')
print(f"Random Forest Cross-Validation Accuracy: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}")
# ---- INTEGRATE CODE FOR BEST MODEL EVALUATION ----

# Assuming best_genre_model is already trained using GridSearchCV
print("Shape of X_test_genre:", X_test_genre.shape)
print("Shape of y_test_genre:", y_test_genre.shape)

# Step 1: Generate predictions and check the shapes
y_pred_genre_best = best_genre_model.predict(X_test_genre)
print("Shape of y_pred_genre_best:", y_pred_genre_best.shape)

# Check if lengths of y_test_genre and y_pred_genre_best match
if len(y_test_genre) != len(y_pred_genre_best):
    print(f"Inconsistent number of samples: y_test_genre = {len(y_test_genre)}, y_pred_genre_best = {len(y_pred_genre_best)}")

# Step 2: Print the classification report if the shapes are consistent
if len(y_test_genre) == len(y_pred_genre_best):
    print("Genre Classification Report (Best Model):")
    print(classification_report(y_test_genre, y_pred_genre_best, target_names=label_encoder_genre.classes_))
else:
    print("Error: Mismatch in the number of samples between y_test_genre and y_pred_genre_best.")

# Mood Prediction
X_mood = sampled_data[audio_features + ['best_cluster']]
y_mood = sampled_data['mood_encoded']

# Split the dataset into training and testing sets
X_train_mood, X_test_mood, y_train_mood, y_test_mood = train_test_split(X_mood, y_mood, test_size=0.6, random_state=42)

# Train and evaluate the model for mood prediction
rf_model_mood = RandomForestClassifier(random_state=42, n_jobs=-1)
rf_model_mood.fit(X_train_mood, y_train_mood)
y_pred_mood = rf_model_mood.predict(X_test_mood)

# Print out the classification report for mood prediction
print("Classification Report - Mood Prediction:")
print(classification_report(y_test_mood, y_pred_mood, target_names=label_encoder_mood.classes_))

# Confusion Matrix for Mood Prediction
cm_mood = confusion_matrix(y_test_mood, y_pred_mood)
disp_mood = ConfusionMatrixDisplay(confusion_matrix=cm_mood, display_labels=label_encoder_mood.classes_)
disp_mood.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=90)
plt.title("Confusion Matrix - Random Forest Mood Prediction")
plt.show()
# Confusion Matrix for Genre Prediction
cm_genre = confusion_matrix(y_test_genre, y_pred_genre)
disp_genre = ConfusionMatrixDisplay(confusion_matrix=cm_genre, display_labels=label_encoder_genre.classes_)
disp_genre.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=90)
plt.title("Confusion Matrix - Random Forest Genre Prediction")
plt.show()

pip install tensorflow

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical

# Ensure the label encoders are initialized
label_encoder_genre = LabelEncoder()
sampled_data['genre_encoded'] = label_encoder_genre.fit_transform(sampled_data['track_genre'])

label_encoder_mood = LabelEncoder()
sampled_data['mood_encoded'] = label_encoder_mood.fit_transform(sampled_data['mood'])

# Features and targets for genre prediction
X = sampled_data[audio_features + ['best_cluster']]  # 'best_cluster' from your clustering method
y_genre = to_categorical(sampled_data['genre_encoded'])  # Convert genre labels to one-hot encoding

# Split the dataset into training and testing sets
X_train_genre, X_test_genre, y_train_genre, y_test_genre = train_test_split(X, y_genre, test_size=0.6, random_state=42)

# Step 8: Define a Neural Network model
nn_model = Sequential()
nn_model.add(Dense(64, activation='relu', input_shape=(X_train_genre.shape[1],)))
nn_model.add(Dropout(0.3))
nn_model.add(Dense(128, activation='relu'))
nn_model.add(Dropout(0.3))
nn_model.add(Dense(y_train_genre.shape[1], activation='softmax'))  # Output layer for multiclass classification

# Step 9: Compile the Neural Network model
nn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Step 10: Train the Neural Network model
history = nn_model.fit(X_train_genre, y_train_genre, epochs=100, validation_data=(X_test_genre, y_test_genre), batch_size=32)

# Step 11: Evaluate the Neural Network model
test_loss, test_acc = nn_model.evaluate(X_test_genre, y_test_genre)
print(f"Test Accuracy for Genre Prediction: {test_acc:.4f}")

# Step 12: Predict on the test set and print the classification report
y_pred_genre = np.argmax(nn_model.predict(X_test_genre), axis=1)
y_test_genre_labels = np.argmax(y_test_genre, axis=1)
print("Classification Report - Neural Network Genre Prediction:")
print(classification_report(y_test_genre_labels, y_pred_genre, target_names=label_encoder_genre.classes_))

# Confusion Matrix for Genre Prediction
cm_genre = confusion_matrix(y_test_genre_labels, y_pred_genre)
disp_genre = ConfusionMatrixDisplay(confusion_matrix=cm_genre, display_labels=label_encoder_genre.classes_)
disp_genre.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=90)
plt.title("Confusion Matrix - Neural Network Genre Prediction")
plt.show()

# Step 13: Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy for Genre Prediction')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss for Genre Prediction')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# ---- Mood Prediction ----

# Prepare data for mood prediction
X_mood = sampled_data[audio_features + ['best_cluster']]
y_mood = to_categorical(sampled_data['mood_encoded'])  # Convert mood labels to one-hot encoding

# Split the dataset into training and testing sets for mood prediction
X_train_mood, X_test_mood, y_train_mood, y_test_mood = train_test_split(X_mood, y_mood, test_size=0.2, random_state=42)

# Step 14: Define a Neural Network model for mood prediction
nn_model_mood = Sequential()
nn_model_mood.add(Dense(64, activation='relu', input_shape=(X_train_mood.shape[1],)))
nn_model_mood.add(Dropout(0.3))
nn_model_mood.add(Dense(128, activation='relu'))
nn_model_mood.add(Dropout(0.3))
nn_model_mood.add(Dense(y_train_mood.shape[1], activation='softmax'))  # Output layer for multiclass classification

# Step 15: Compile the Neural Network model for mood prediction
nn_model_mood.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Step 16: Train the Neural Network model for mood prediction
history_mood = nn_model_mood.fit(X_train_mood, y_train_mood, epochs=100, validation_data=(X_test_mood, y_test_mood), batch_size=32)

# Step 17: Evaluate the Neural Network model for mood prediction
test_loss_mood, test_acc_mood = nn_model_mood.evaluate(X_test_mood, y_test_mood)
print(f"Test Accuracy for Mood Prediction: {test_acc_mood:.4f}")

# Step 18: Predict on the test set and print the classification report
y_pred_mood = np.argmax(nn_model_mood.predict(X_test_mood), axis=1)
y_test_mood_labels = np.argmax(y_test_mood, axis=1)
print("Classification Report - Neural Network Mood Prediction:")
print(classification_report(y_test_mood_labels, y_pred_mood, target_names=label_encoder_mood.classes_))

# Confusion Matrix for Mood Prediction
cm_mood = confusion_matrix(y_test_mood_labels, y_pred_mood)
disp_mood = ConfusionMatrixDisplay(confusion_matrix=cm_mood, display_labels=label_encoder_mood.classes_)
disp_mood.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=90)
plt.title("Confusion Matrix - Neural Network Mood Prediction")
plt.show()

# Plot training & validation accuracy values for mood prediction
plt.plot(history_mood.history['accuracy'])
plt.plot(history_mood.history['val_accuracy'])
plt.title('Model accuracy for Mood Prediction')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# Plot training & validation loss values for mood prediction
plt.plot(history_mood.history['loss'])
plt.plot(history_mood.history['val_loss'])
plt.title('Model loss for Mood Prediction')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# --- Feature Extraction using Librosa (Snippet 2) ---

# Define a function to extract features from an audio file and predict its genre and mood
def extract_librosa_features(file_path):
    y, sr = librosa.load(file_path, duration=150)  # Load the first 90 seconds of the audio file
    features = {}

    # Extract tempo
    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
    features['tempo'] = tempo

    # Extract energy
    rms = librosa.feature.rms(y=y)
    features['energy'] = np.mean(rms)

    # Approximate loudness using spectral flatness or RMS as an alternative
    features['loudness'] = np.mean(librosa.feature.spectral_flatness(y=y))

    # Valence approximation using zero crossing rate
    zcr = librosa.feature.zero_crossing_rate(y=y)
    features['valence'] = np.mean(zcr)

    # Danceability approximation using the tempogram (as you initially used)
    onset_env = librosa.onset.onset_strength(y=y, sr=sr)
    tempogram = librosa.feature.tempogram(onset_envelope=onset_env, sr=sr)
    features['danceability'] = np.mean(tempogram)

    # Extract MFCCs (Mean of the first 13 coefficients)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    for i in range(1, 14):
        features[f'mfcc_{i}'] = np.mean(mfccs[i-1])

    # Extract Chroma features (Mean value across all chroma bands)
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)
    features['chroma'] = np.mean(chroma)

    # Extract Spectral Contrast (Mean value across all spectral contrast bands)
    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)
    for i in range(1, spectral_contrast.shape[0] + 1):
        features[f'spectral_contrast_{i}'] = np.mean(spectral_contrast[i-1])

    # Convert the extracted features to a DataFrame with appropriate column names
    feature_vector = pd.DataFrame([features])

    return feature_vector

# Load and preprocess the uploaded song to extract its features
uploaded_song_path = '/content/drive/MyDrive/The Chainsmokers - Closer (Lyric) ft. Halsey (128).mp3'  # Replace with actual path
librosa_features = extract_librosa_features(uploaded_song_path)

# Only scale and use the original features for prediction
original_features = ['danceability', 'energy', 'loudness', 'valence', 'tempo']
filtered_features = librosa_features[original_features]
filtered_features['best_cluster'] = 0  # Adding a dummy column to match the model input

# Scale the filtered features using the same scaler as used for training the model
scaler = StandardScaler().fit(X)  # Assuming X was scaled during training
librosa_features_scaled = scaler.transform(filtered_features)

# Convert the scaled features back to a DataFrame to retain the correct column names
librosa_features_scaled_df = pd.DataFrame(librosa_features_scaled, columns=filtered_features.columns)

# Predict the genre of the uploaded song using the trained genre model
predicted_genre = np.argmax(nn_model.predict(librosa_features_scaled_df), axis=1)
predicted_genre_label = label_encoder_genre.inverse_transform(predicted_genre)

# Predict the mood of the uploaded song using the trained mood model
predicted_mood = np.argmax(nn_model_mood.predict(librosa_features_scaled_df), axis=1)
predicted_mood_label = label_encoder_mood.inverse_transform(predicted_mood)

# Display the predicted genre and mood of the uploaded song
print(f"Predicted Genre: {predicted_genre_label[0]}")
print(f"Predicted Mood: {predicted_mood_label[0]}")

# --- Visualizations: Spectrogram, MFCCs, Chroma Features ---
# Spectrogram visualization
y, sr = librosa.load(uploaded_song_path, duration=90)
D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
plt.figure(figsize=(14, 6))
librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='magma')
plt.colorbar(format='%+2.0f dB')
plt.title('Spectrogram (Log Scale)')
plt.tight_layout()
plt.show()

# MFCCs visualization (redefine mfccs here)
mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
plt.figure(figsize=(10, 6))
librosa.display.specshow(mfccs, sr=sr, x_axis='time')
plt.colorbar()
plt.title('MFCCs')
plt.tight_layout()
plt.show()

# Chroma Features visualization
chroma = librosa.feature.chroma_stft(y=y, sr=sr)
plt.figure(figsize=(10, 6))
librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', sr=sr)
plt.colorbar()
plt.title('Chroma Features')
plt.tight_layout()
plt.show()

"""# Implementing Librosa and Extracting Features followed by Genre and Mood"""

import pickle
model_save_path = '/content/drive/MyDrive/best_genre_model.pkl'
with open(model_save_path, 'wb') as f:
    pickle.dump(best_genre_model, f)

print(f"Best Genre Model saved at: {model_save_path}")

model_save_path = '/content/drive/MyDrive/mood_model.pkl'
with open(model_save_path, 'wb') as f:
    pickle.dump(mood_model, f)

print(f"Mood Model saved at: {model_save_path}")

scaler_save_path = '/content/drive/MyDrive/scaler.pkl'
with open(scaler_save_path, 'wb') as f:
    pickle.dump(scaler, f)

print(f"Scaler saved at: {scaler_save_path}")

label_encoder_genre_save_path = '/content/drive/MyDrive/label_encoder_genre.pkl'
with open(label_encoder_genre_save_path, 'wb') as f:
    pickle.dump(label_encoder_genre, f)

print(f"Label Encoder for Genre saved at: {label_encoder_genre_save_path}")

label_encoder_mood_save_path = '/content/drive/MyDrive/label_encoder_mood.pkl'
with open(label_encoder_mood_save_path, 'wb') as f:
    pickle.dump(label_encoder_mood, f)

print(f"Label Encoder for Mood saved at: {label_encoder_mood_save_path}")

import pandas as pd
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score
from sklearn.preprocessing import LabelEncoder, StandardScaler

# ---- PART 1: RandomForest Model for Genre and Mood Prediction ----

# Assuming sampled_data and audio_features are already available in the dataset
audio_features = ['danceability', 'energy', 'loudness', 'valence', 'tempo']

# Initialize label encoders
label_encoder_genre = LabelEncoder()
sampled_data['genre_encoded'] = label_encoder_genre.fit_transform(sampled_data['track_genre'])

label_encoder_mood = LabelEncoder()
sampled_data['mood_encoded'] = label_encoder_mood.fit_transform(sampled_data['mood'])

# Features and targets for genre prediction
X = sampled_data[audio_features + ['best_cluster']]  # 'best_cluster' from the best method
y_genre = sampled_data['genre_encoded']

# Split the dataset into training and testing sets
X_train_genre, X_test_genre, y_train_genre, y_test_genre = train_test_split(X, y_genre, test_size=0.4, random_state=42)

# Step 1: Define and train a Random Forest model for genre prediction
rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)
rf_model.fit(X_train_genre, y_train_genre)  # Ensure the model is trained before predicting

# Step 2: Make predictions for genre
y_pred_genre = rf_model.predict(X_test_genre)

# Step 3: Print classification report and confusion matrix for genre
print("Classification Report - Genre Prediction:")
print(classification_report(y_test_genre, y_pred_genre, target_names=label_encoder_genre.classes_))

cm_genre = confusion_matrix(y_test_genre, y_pred_genre)
disp_genre = ConfusionMatrixDisplay(confusion_matrix=cm_genre, display_labels=label_encoder_genre.classes_)
disp_genre.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=90)
plt.title("Confusion Matrix - Random Forest Genre Prediction")
plt.show()

# Step 4: Plot feature importance for genre prediction
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]
plt.figure()
plt.title("Feature Importances")
plt.bar(range(X_train_genre.shape[1]), importances[indices], color="r", align="center")
plt.xticks(range(X_train_genre.shape[1]), [X.columns[i] for i in indices], rotation=90)
plt.xlim([-1, X_train_genre.shape[1]])
plt.show()

# ---- Mood Prediction ----

# Prepare data for mood prediction
X_mood = sampled_data[audio_features + ['best_cluster']]
y_mood = sampled_data['mood_encoded']

# Split the dataset into training and testing sets for mood prediction
X_train_mood, X_test_mood, y_train_mood, y_test_mood = train_test_split(X_mood, y_mood, test_size=0.2, random_state=42)

# Train and evaluate the model for mood prediction
rf_model_mood = RandomForestClassifier(random_state=42, n_jobs=-1)
rf_model_mood.fit(X_train_mood, y_train_mood)
y_pred_mood = rf_model_mood.predict(X_test_mood)

# Print out the classification report for mood prediction
print("Classification Report - Mood Prediction:")
print(classification_report(y_test_mood, y_pred_mood, target_names=label_encoder_mood.classes_))

# Confusion Matrix for Mood Prediction
cm_mood = confusion_matrix(y_test_mood, y_pred_mood)
disp_mood = ConfusionMatrixDisplay(confusion_matrix=cm_mood, display_labels=label_encoder_mood.classes_)
disp_mood.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=90)
plt.title("Confusion Matrix - Random Forest Mood Prediction")
plt.show()

# ---- PART 2: Feature Extraction using Librosa and RandomForest Prediction ----

# Define a function to extract features from an audio file and predict its genre and mood
def extract_librosa_features(file_path):
    y, sr = librosa.load(file_path, duration=150)  # Load the first 90 seconds of the audio file
    features = {}

    # Extract features using librosa
    features['tempo'] = librosa.beat.tempo(y=y, sr=sr)[0]
    features['energy'] = np.mean(librosa.feature.rms(y=y))
    features['loudness'] = np.mean(librosa.feature.spectral_flatness(y=y))
    features['valence'] = np.mean(librosa.feature.zero_crossing_rate(y=y))
    features['danceability'] = np.mean(librosa.feature.tempogram(onset_envelope=librosa.onset.onset_strength(y=y, sr=sr), sr=sr))

    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    for i in range(1, 14):
        features[f'mfcc_{i}'] = np.mean(mfccs[i-1])

    chroma = librosa.feature.chroma_stft(y=y, sr=sr)
    features['chroma'] = np.mean(chroma)

    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)
    for i in range(1, spectral_contrast.shape[0] + 1):
        features[f'spectral_contrast_{i}'] = np.mean(spectral_contrast[i-1])

    return pd.DataFrame([features])

# Load and preprocess the uploaded song to extract its features
uploaded_song_path = '/content/drive/MyDrive/Ariana Grande - 7 rings (Official Video) (128).mp3'  # Replace with actual path
librosa_features = extract_librosa_features(uploaded_song_path)

# Only scale and use the original features for prediction
original_features = ['danceability', 'energy', 'loudness', 'valence', 'tempo']
filtered_features = librosa_features[original_features]
filtered_features['best_cluster'] = 0  # Adding a dummy column to match the model input

# Scale the filtered features using the same scaler as used for training the model
scaler = StandardScaler().fit(X)  # Assuming X was scaled during training
librosa_features_scaled = scaler.transform(filtered_features)

# Convert the scaled features back to a DataFrame to retain the correct column names
librosa_features_scaled_df = pd.DataFrame(librosa_features_scaled, columns=filtered_features.columns)

# Predict the genre of the uploaded song using the trained genre model
predicted_genre = rf_model.predict(librosa_features_scaled_df)  # Now the model is already trained
predicted_genre_label = label_encoder_genre.inverse_transform(predicted_genre)

# Predict the mood of the uploaded song using the trained mood model
predicted_mood = rf_model_mood.predict(librosa_features_scaled_df)
predicted_mood_label = label_encoder_mood.inverse_transform(predicted_mood)

# Display the predicted genre and mood of the uploaded song
print(f"Predicted Genre: {predicted_genre_label[0]}")
print(f"Predicted Mood: {predicted_mood_label[0]}")

# ---- Visualizations: Spectrogram, MFCCs, Chroma Features ----

# Spectrogram visualization
y, sr = librosa.load(uploaded_song_path, duration=90)
D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)
plt.figure(figsize=(14, 6))
librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='magma')
plt.colorbar(format='%+2.0f dB')
plt.title('Spectrogram (Log Scale)')
plt.tight_layout()
plt.show()

# MFCCs visualization
plt.figure(figsize=(10, 6))
librosa.display.specshow(mfccs, sr=sr, x_axis='time')
plt.colorbar()
plt.title('MFCCs')
plt.tight_layout()
plt.show()

# Chroma Features visualization
chroma = librosa.feature.chroma_stft(y=y, sr=sr)
plt.figure(figsize=(10, 6))
librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', sr=sr)
plt.colorbar()
plt.title('Chroma Features')
plt.tight_layout()
plt.show()

"""# Frontend User Interface Development

"""

!pip install flask-ngrok
!pip install flask
!pip install librosa
!pip install scikit-learn
!pip install pyngrok

!ngrok config add-authtoken "'''PLEASE ADD YOUR AUTHENTICATION TOKEN'''"

html_templates = '''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Music Genre & Mood Prediction</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap');

        /* Global styling */
        body {
            font-family: 'Poppins', sans-serif;
            background: linear-gradient(135deg, #ff9a9e 0%, #fad0c4 100%);
            color: #333;
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            overflow: hidden;
            position: relative;
        }

        /* Floating background circles */
        .circle {
            position: absolute;
            border-radius: 50%;
            background: rgba(255, 255, 255, 0.2);
            z-index: -1;
            animation: float 15s infinite ease-in-out;
        }

        @keyframes float {
            0% { transform: translateY(0); }
            50% { transform: translateY(-20px); }
            100% { transform: translateY(0); }
        }

        .circle1 {
            width: 300px;
            height: 300px;
            top: 10%;
            left: -10%;
            animation-delay: 2s;
        }

        .circle2 {
            width: 500px;
            height: 500px;
            bottom: 5%;
            right: -15%;
            animation-delay: 4s;
        }

        /* Floating card effect */
        .wrapper {
            background: rgba(255, 255, 255, 0.9); /* Frosted glass effect */
            border-radius: 20px;
            box-shadow: 0 8px 30px rgba(0, 0, 0, 0.2);
            max-width: 600px;
            width: 100%;
            padding: 40px;
            text-align: center;
            position: relative;
            z-index: 1;
            backdrop-filter: blur(10px);
        }

        header {
            font-weight: 700;
            font-size: 26px;
            color: #ff5f6d;
            padding-bottom: 20px;
            border-bottom: 1px solid rgba(0, 0, 0, 0.1);
            margin-bottom: 20px;
        }

        .container h1 {
            font-size: 24px;
            color: #ff5f6d;
            margin-bottom: 20px;
        }

        label {
            font-size: 18px;
            color: #555;
            display: block;
            text-align: left;
            margin-bottom: 10px;
        }

        input[type="file"] {
            width: 100%;
            padding: 12px;
            margin-bottom: 20px;
            font-size: 16px;
            border-radius: 10px;
            border: 1px solid #ddd;
            box-shadow: inset 0 3px 6px rgba(0, 0, 0, 0.05);
            transition: border 0.3s ease;
        }

        input[type="file"]:hover {
            border: 1px solid #aaa;
        }

        input[type="submit"] {
            width: 100%;
            padding: 15px;
            font-size: 18px;
            font-weight: 600;
            background-color: #ff5f6d;
            color: white;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            transition: background-color 0.3s ease, transform 0.2s ease;
        }

        input[type="submit"]:hover {
            background-color: #ff2a3c;
            transform: translateY(-2px);
        }

        .feedback-buttons {
            margin-top: 20px;
        }

        .feedback-buttons button {
            font-size: 16px;
            padding: 10px 20px;
            margin: 10px;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }

        .like-button {
            background-color: #4CAF50;
            color: white;
        }

        .like-button:hover {
            background-color: #45a049;
        }

        .dislike-button {
            background-color: #f44336;
            color: white;
        }

        .dislike-button:hover {
            background-color: #e53935;
        }

        footer {
            margin-top: 20px;
            font-size: 14px;
            color: #555;
        }

    </style>
</head>
<body>

<div class="wrapper">
    <header>🎵 Music Genre & Mood Predictor</header>

    <div class="container">
        <h1>Prediction Results</h1>
        <p><strong>Predicted Genre:</strong> {{ genre }}</p>
        <p><strong>Predicted Mood:</strong> {{ mood }}</p>

        <div class="feedback-buttons">
            <form action="/feedback" method="POST">
                <input type="hidden" name="genre" value="{{ genre }}">
                <input type="hidden" name="mood" value="{{ mood }}">
                <button class="like-button" name="feedback" value="like">👍 Like</button>
                <button class="dislike-button" name="feedback" value="dislike">👎 Dislike</button>
            </form>
        </div>

        {% if feedback == 'dislike' %}
        <div>
            <h3>Help us improve! What should the correct genre or mood be?</h3>
            <form action="/submit_correction" method="POST">
                <label for="correct_genre">Correct Genre:</label>
                <input type="text" name="correct_genre" id="correct_genre">

                <label for="correct_mood">Correct Mood:</label>
                <input type="text" name="correct_mood" id="correct_mood">

                <input type="submit" value="Submit Correction">
            </form>
        </div>
        {% endif %}
    </div>

    <footer>
        Powered by Flask & Librosa
    </footer>
</div>

<div class="circle circle1"></div>
<div class="circle circle2"></div>

</body>
</html>
'''

# Save the updated HTML content to the respective file
with open('/content/templates/result.html', 'w') as file:
    file.write(html_templates)

import os

# Define the directory path
directory = '/content/templates/'

# Check if the directory exists, if not, create it
if not os.path.exists(directory):
    os.makedirs(directory)

# Save the HTML content to the respective file
with open(os.path.join(directory, 'upload_or_link.html'), 'w') as file:
    file.write(html_templates)

print("File saved successfully!")

html_templates = '''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Music Genre & Mood Prediction</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap');

        /* Global styling */
        body {
            font-family: 'Poppins', sans-serif;
            background: linear-gradient(135deg, #ff9a9e 0%%, #fad0c4 100%%);
            color: #333;
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            overflow: hidden;
            position: relative;
        }

        /* Floating background circles */
        .circle {
            position: absolute;
            border-radius: 50%%;
            background: rgba(255, 255, 255, 0.2);
            z-index: -1;
            animation: float 15s infinite ease-in-out;
        }

        @keyframes float {
            0%% { transform: translateY(0); }
            50%% { transform: translateY(-20px); }
            100%% { transform: translateY(0); }
        }

        .circle1 {
            width: 300px;
            height: 300px;
            top: 10%%;
            left: -10%%;
            animation-delay: 2s;
        }

        .circle2 {
            width: 500px;
            height: 500px;
            bottom: 5%%;
            right: -15%%;
            animation-delay: 4s;
        }

        /* Floating card effect */
        .wrapper {
            background: rgba(255, 255, 255, 0.9); /* Frosted glass effect */
            border-radius: 20px;
            box-shadow: 0 8px 30px rgba(0, 0, 0, 0.2);
            max-width: 600px;
            width: 100%%;
            padding: 40px;
            text-align: center;
            position: relative;
            z-index: 1;
            backdrop-filter: blur(10px);
        }

        header {
            font-weight: 700;
            font-size: 26px;
            color: #ff5f6d;
            padding-bottom: 20px;
            border-bottom: 1px solid rgba(0, 0, 0, 0.1);
            margin-bottom: 20px;
        }

        .container h1 {
            font-size: 24px;
            color: #ff5f6d;
            margin-bottom: 20px;
        }

        label {
            font-size: 18px;
            color: #555;
            display: block;
            text-align: left;
            margin-bottom: 10px;
        }

        input[type="file"], input[type="text"] {
            width: 100%%;
            padding: 12px;
            margin-bottom: 20px;
            font-size: 16px;
            border-radius: 10px;
            border: 1px solid #ddd;
            box-shadow: inset 0 3px 6px rgba(0, 0, 0, 0.05);
            transition: border 0.3s ease;
        }

        input[type="file"]:hover, input[type="text"]:hover {
            border: 1px solid #aaa;
        }

        input[type="submit"] {
            width: 100%%;
            padding: 15px;
            font-size: 18px;
            font-weight: 600;
            background-color: #ff5f6d;
            color: white;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            transition: background-color 0.3s ease, transform 0.2s ease;
        }

        input[type="submit"]:hover {
            background-color: #ff2a3c;
            transform: translateY(-2px);
        }

        .feedback-buttons {
            margin-top: 20px;
        }

        .feedback-buttons button {
            font-size: 16px;
            padding: 10px 20px;
            margin: 10px;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }

        .like-button {
            background-color: #4CAF50;
            color: white;
        }

        .like-button:hover {
            background-color: #45a049;
        }

        .dislike-button {
            background-color: #f44336;
            color: white;
        }

        .dislike-button:hover {
            background-color: #e53935;
        }

        footer {
            margin-top: 20px;
            font-size: 14px;
            color: #555;
        }

    </style>
</head>
<body>

<div class="wrapper">
    <header>🎵 Music Genre & Mood Predictor</header>

    <div class="container">
        <h1>Prediction Results</h1>
        <p><strong>Predicted Genre:</strong> {{ genre }}</p>
        <p><strong>Predicted Mood:</strong> {{ mood }}</p>

        <div class="feedback-buttons">
            <form action="/feedback" method="POST">
                <input type="hidden" name="genre" value="{{ genre }}">
                <input type="hidden" name="mood" value="{{ mood }}">
                <button class="like-button" name="feedback" value="like">👍 Like</button>
                <button class="dislike-button" name="feedback" value="dislike">👎 Dislike</button>
            </form>
        </div>

        {% if feedback == 'dislike' %}
        <div>
            <h3>Help us improve! What should the correct genre or mood be?</h3>
            <form action="/submit_correction" method="POST">
                <label for="correct_genre">Correct Genre:</label>
                <input type="text" name="correct_genre" id="correct_genre">

                <label for="correct_mood">Correct Mood:</label>
                <input type="text" name="correct_mood" id="correct_mood">

                <input type="submit" value="Submit Correction">
            </form>
        </div>
        {% endif %}
    </div>

    <footer>
        Powered by Flask & Librosa
    </footer>
</div>

<div class="circle circle1"></div>
<div class="circle circle2"></div>

</body>
</html>
'''

# Save the HTML content to the respective file
with open('/content/templates/result.html', 'w') as file:
    file.write(html_templates)

def get_feedback_stats():
    conn = sqlite3.connect('feedback.db')
    cursor = conn.cursor()

    # Count the total feedback entries
    cursor.execute('SELECT COUNT(*) FROM feedback')
    total_feedback = cursor.fetchone()[0]

    # Count the number of likes
    cursor.execute('SELECT COUNT(*) FROM feedback WHERE feedback = "like"')
    total_likes = cursor.fetchone()[0]

    # Count the number of dislikes
    cursor.execute('SELECT COUNT(*) FROM feedback WHERE feedback = "dislike"')
    total_dislikes = cursor.fetchone()[0]

    # Get underperforming genres/moods
    cursor.execute('SELECT genre, mood, COUNT(*) FROM feedback WHERE feedback = "dislike" GROUP BY genre, mood')
    underperforming = cursor.fetchall()

    conn.close()

    return {
        "total_feedback": total_feedback,
        "total_likes": total_likes,
        "total_dislikes": total_dislikes,
        "underperforming": underperforming
    }

def generate_report():
    stats = get_feedback_stats()

    print(f"Total feedback received: {stats['total_feedback']}")
    print(f"Total likes: {stats['total_likes']}")
    print(f"Total dislikes: {stats['total_dislikes']}")

    print("Underperforming genres/moods based on user dislikes:")
    for row in stats['underperforming']:
        print(f"Genre: {row[0]}, Mood: {row[1]}, Dislikes: {row[2]}")

import os
from flask import Flask, request, render_template, redirect, jsonify
from pyngrok import ngrok
import librosa
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import traceback
import librosa.display
import sqlite3
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import SpectralClustering
import pickle

# Initialize the Flask app
app = Flask(__name__, template_folder='/content/templates')

# Load models, scaler, and label encoders
best_genre_model = pickle.load(open('/content/drive/MyDrive/best_genre_model.pkl', 'rb'))
mood_model = pickle.load(open('/content/drive/MyDrive/mood_model.pkl', 'rb'))
scaler = pickle.load(open('/content/drive/MyDrive/scaler.pkl', 'rb'))
label_encoder_genre = pickle.load(open('/content/drive/MyDrive/label_encoder_genre.pkl', 'rb'))
label_encoder_mood = pickle.load(open('/content/drive/MyDrive/label_encoder_mood.pkl', 'rb'))

# Connect to the SQLite database
def init_db():
    conn = sqlite3.connect('feedback.db')
    cursor = conn.cursor()
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS feedback (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        genre TEXT,
        mood TEXT,
        feedback TEXT,
        correct_genre TEXT,
        correct_mood TEXT
    )
    ''')
    conn.commit()
    conn.close()

# Define the route for the main page (upload or link)
@app.route('/', methods=['GET', 'POST'])
def upload_or_link():
    if request.method == 'POST':
        file_path = None

        # Handle file upload
        if 'file' in request.files and request.files['file'].filename != '':
            file = request.files['file']
            file_path = os.path.join('/content', file.filename)
            file.save(file_path)
            print(f"File saved at: {file_path}")

        else:
            return "Please upload a file."

        if file_path:
            return process_and_predict(file_path)
        else:
            return "File upload failed."

    return render_template('upload_or_link.html')

# Define a function to extract features from an audio file and predict its genre and mood
def extract_librosa_features(file_path):
    y, sr = librosa.load(file_path, duration=90)  # Load the first 90 seconds of the audio file
    features = {}

    # Extract tempo
    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
    features['tempo'] = tempo

    # Extract energy
    rms = librosa.feature.rms(y=y)
    features['energy'] = np.mean(rms)

    # Approximate loudness using spectral flatness
    features['loudness'] = np.mean(librosa.feature.spectral_flatness(y=y))

    # Valence approximation using zero crossing rate
    zcr = librosa.feature.zero_crossing_rate(y=y)
    features['valence'] = np.mean(zcr)

    # Danceability approximation using the tempogram
    onset_env = librosa.onset.onset_strength(y=y, sr=sr)
    tempogram = librosa.feature.tempogram(onset_envelope=onset_env, sr=sr)
    features['danceability'] = np.mean(tempogram)

    # Extract MFCCs (Mean of the first 13 coefficients)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    for i in range(1, 14):
        features[f'mfcc_{i}'] = np.mean(mfccs[i-1])

    # Extract Chroma features (Mean value across all chroma bands)
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)
    features['chroma'] = np.mean(chroma)

    # Extract Spectral Contrast (Mean value across all spectral contrast bands)
    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)
    for i in range(1, spectral_contrast.shape[0] + 1):
        features[f'spectral_contrast_{i}'] = np.mean(spectral_contrast[i-1])

    # Convert the extracted features to a DataFrame
    feature_vector = pd.DataFrame([features])
    return feature_vector

def process_and_predict(file_path):
    try:
        # Extract audio features
        librosa_features = extract_librosa_features(file_path)
        original_features = ['danceability', 'energy', 'loudness', 'valence', 'tempo']
        filtered_features = librosa_features[original_features]

        # Add dummy 'best_cluster' column if needed (for compatibility)
        filtered_features['best_cluster'] = 0

        # Scale features
        librosa_features_scaled = scaler.transform(filtered_features)
        librosa_features_scaled_df = pd.DataFrame(librosa_features_scaled, columns=filtered_features.columns)

        # Predict genre and mood using pre-trained models
        predicted_genre = best_genre_model.predict(librosa_features_scaled_df)
        predicted_genre_label = label_encoder_genre.inverse_transform(predicted_genre)

        predicted_mood = mood_model.predict(librosa_features_scaled_df)
        predicted_mood_label = label_encoder_mood.inverse_transform(predicted_mood)

        # Render the results page with predicted genre and mood
        return render_template('result.html',
                               genre=predicted_genre_label[0],
                               mood=predicted_mood_label[0])

    except Exception as e:
        print("Error during processing:")
        traceback.print_exc()
        return "An error occurred during processing. Please try again."


# Handle user feedback (like/dislike)
@app.route('/feedback', methods=['POST'])
def feedback():
    genre = request.form['genre']
    mood = request.form['mood']
    user_feedback = request.form['feedback']

    if user_feedback == 'like':
        store_feedback(genre, mood, user_feedback)
        return redirect('/')
    elif user_feedback == 'dislike':
        return render_template('result.html', genre=genre, mood=mood, feedback='dislike')

# Handle submission of corrections
@app.route('/submit_correction', methods=['POST'])
def submit_correction():
    correct_genre = request.form['correct_genre']
    correct_mood = request.form['correct_mood']
    genre = request.form.get('genre')
    mood = request.form.get('mood')

    store_feedback(genre, mood, 'dislike', correct_genre, correct_mood)
    return redirect('/')

# Store feedback in the database
def store_feedback(genre, mood, feedback, correct_genre=None, correct_mood=None):
    conn = sqlite3.connect('feedback.db')
    cursor = conn.cursor()
    cursor.execute('''
    INSERT INTO feedback (genre, mood, feedback, correct_genre, correct_mood)
    VALUES (?, ?, ?, ?, ?)
    ''', (genre, mood, feedback, correct_genre, correct_mood))
    conn.commit()
    conn.close()

# Generate visualizations and save them as images
def generate_visualizations(file_path):
    visualizations = {}

    # Visualization: Spectrogram
    y, sr = librosa.load(file_path, duration=90)
    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)

    plt.figure(figsize=(14, 6))
    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log', cmap='magma')
    plt.colorbar(format='%+2.0f dB')
    plt.title('Spectrogram (Log Scale)')
    plt.tight_layout()
    spectrogram_path = '/content/spectrogram.png'
    plt.savefig(spectrogram_path)
    visualizations['spectrogram'] = spectrogram_path
    plt.close()

    # Visualization: MFCCs Plot
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

    plt.figure(figsize=(10, 6))
    librosa.display.specshow(mfccs, sr=sr, x_axis='time')
    plt.colorbar()
    plt.title('MFCCs')
    plt.tight_layout()
    mfcc_path = '/content/mfcc.png'
    plt.savefig(mfcc_path)
    visualizations['mfcc'] = mfcc_path
    plt.close()

    # Visualization: Chroma Features Plot
    chroma = librosa.feature.chroma_stft(y=y, sr=sr)

    plt.figure(figsize=(10, 6))
    librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', sr=sr)
    plt.colorbar()
    plt.title('Chroma Features')
    plt.tight_layout()
    chroma_path = '/content/chroma.png'
    plt.savefig(chroma_path)
    visualizations['chroma'] = chroma_path
    plt.close()

    return visualizations

# Feedback analytics and reporting
def get_feedback_stats():
    conn = sqlite3.connect('feedback.db')
    cursor = conn.cursor()

    cursor.execute('SELECT COUNT(*) FROM feedback')
    total_feedback = cursor.fetchone()[0]

    cursor.execute('SELECT COUNT(*) FROM feedback WHERE feedback = "like"')
    total_likes = cursor.fetchone()[0]

    cursor.execute('SELECT COUNT(*) FROM feedback WHERE feedback = "dislike"')
    total_dislikes = cursor.fetchone()[0]

    cursor.execute('''
        SELECT genre, mood, COUNT(*)
        FROM feedback
        WHERE feedback = "dislike"
        GROUP BY genre, mood
        ORDER BY COUNT(*) DESC
    ''')
    disliked_entries = cursor.fetchall()

    conn.close()

    return {
        'total_feedback': total_feedback,
        'total_likes': total_likes,
        'total_dislikes': total_dislikes,
        'disliked_entries': disliked_entries
    }

# Route to view feedback analytics
@app.route('/analytics')
def view_analytics():
    stats = get_feedback_stats()
    return jsonify(stats)

# Route to generate feedback report
@app.route('/generate_report')
def generate_report():
    report = generate_feedback_report()
    return report

# Generate feedback report
def generate_feedback_report():
    stats = get_feedback_stats()

    report = f"""
    Feedback Report:
    ----------------
    Total Feedback Received: {stats['total_feedback']}
    Total Likes: {stats['total_likes']}
    Total Dislikes: {stats['total_dislikes']}

    Underperforming Genres and Moods (based on dislikes):
    -----------------------------------------------------
    """

    if stats['disliked_entries']:
        for entry in stats['disliked_entries']:
            report += f"Genre: {entry[0]}, Mood: {entry[1]} - Dislikes: {entry[2]}\n"
    else:
        report += "No underperforming genres or moods identified.\n"

    with open('feedback_report.txt', 'w') as f:
        f.write(report)

    return report

# Start the Flask app
if __name__ == '__main__':
    public_url = ngrok.connect(5000)
    print(f" * ngrok tunnel \"{public_url}\" -> \"http://127.0.0.1:5000\"")
    init_db()  # Initialize the database
    app.run(port=5000)